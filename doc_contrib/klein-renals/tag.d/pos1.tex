\title{Part-of-speech tagging (1)}
\author{Steve Renals \newline \mbox{ }s.renals@ed.ac.uk\mbox{ }}
\date{ICL --- 13 October 2005}

\begin{document}

\frame{\titlepage}



\mode<article>{\section[Outline]{ICL/PoS Tagging 1/2005--10--13}}
\mode<presentation>{
  \section[Outline]{}
}

\frame{\tableofcontents}

\section{Parts of Speech}

\subsection{Introduction}

\begin{frame}
   \mode<presentation>{\frametitle{Parts of speech}}

  \begin{itemize}
  \item How can we predict the bahaviour of a previously unseen word?
  \item Words can be divided into classes that behave similarly.
  \item Traditionally eight parts of speech: noun, verb,
    pronoun, preposition, adverb, conjunction, adjective and article.
  \item More recently larger sets have been used: eg Penn Treebank (45
    tags), Susanne (353 tags).
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Parts of Speech}

  \begin{alertblock}{What use are parts of speech?}
    They tell us a lot about a word (and the words near it).
  \end{alertblock}

  \pause
  \begin{itemize}
  \item Tell us what words are likely to occur in the neighbourhood
    (eg adjectives often followed by nouns, personal pronouns often
    followed by verbs, possessive pronouns by nouns)
  \item Pronunciations can be dependent on part of speech, eg
    \textcolor{black}{object, content, discount} (useful for speech
    synthesis and speech recognition)
  \item Can help information retrieval and extraction (stemming,
    partial parsing) 
  \item Useful component in many NLP systems
  \end{itemize}
  
\end{frame}

\subsection{Open and closed classes}

\begin{frame}
   \mode<presentation>{\frametitle{Closed and open classes}}
  \begin{itemize}
  \item Parts of speech may be categorised as \emph{open} or
    \emph{closed} classes
  \item Closed classes have a fixed membership of words (more or
    less), eg determiners, pronouns, prepositions
  \item Closed class words are usually \emph{function words} ---
    frequently occurring, grammatically important, often short (eg
    \textcolor{black}{of,it,the,in})
  \item The major open classes are \emph{nouns}, \emph{verbs},
    \emph{adjectives} and \emph{adverbs}
  \end{itemize}
\end{frame}

\begin{frame}
  \frametitle{Closed classes in English}
  \begin{description}
  \item[prepositions] on, under, over, to, with, by
  \item[determiners] the, a, an, some
  \item[pronouns] she, you, I, who
  \item[conjunctions] and, but, or, as, when, if
  \item[auxiliary verbs] can, may, are
  \item[particles] up, down, at, by
  \item[numerals] one, two, first, second
  \end{description}
\end{frame}

\begin{frame}
  \frametitle{Open classes}
  \begin{description}
  \item[nouns] Proper nouns (\textcolor{black}{Scotland}, \textcolor{black}{BBC}),\\
    common nouns:
    \begin{itemize}
    \item count nouns (\textcolor{black}{goat},
      \textcolor{black}{glass})
    \item mass nouns (\textcolor{black}{snow},
      \textcolor{black}{pacifism})
    \end{itemize}
  \item[verbs] actions and processes (\textcolor{black}{run},
    \textcolor{black}{hope}), also auxiliary verbs
  \item[adjectives] properties and qualities (age, colour, value)
  \item[adverbs] modify verbs, or verb phrases, or other adverbs:\\
    \textcolor{black}{\emph{Unfortunately} John walked \emph{home
        extremely slowly yesterday}}
  \end{description}
\end{frame}


\subsection{Tagsets}

\begin{frame}
  \frametitle{The Penn Treebank tagset (1)}
  {\footnotesize
    \begin{tabular}{|lll|lll|}
      \hline
      CC & Coord Conjuncn & \emph{and,but,or} &  
      NN & Noun, sing. or mass & \emph{dog} \\
      CD & Cardinal number & \emph{one,two} & 
      NNS & Noun, plural & \emph{dogs} \\
      DT & Determiner & \emph{the,some} &  
      NNP & Proper noun, sing. & \emph{Edinburgh} \\
      EX & Existential there & \emph{there} &  
      NNPS & Proper noun, plural & \emph{Orkneys} \\
      FW & Foreign Word & \emph{mon dieu} &  
      PDT & Predeterminer & \emph{all, both}\\
      IN & Preposition & \emph{of,in,by} & 
      POS & Possessive ending & \emph{'s} \\
      JJ & Adjective & \emph{big} & 
      PP & Personal pronoun & \emph{I,you,she} \\
      JJR & Adj., comparative & \emph{bigger} & 
      PP\$ & Possessive pronoun & \emph{my,one's} \\
      JJS & Adj., superlative & \emph{biggest} &  
      RB & Adverb & \emph{quickly} \\
      LS & List item marker & \emph{1,One} &  
      RBR & Adverb, comparative & \emph{faster} \\
      MD & Modal & \emph{can,should} &
      RBS & Adverb, superlative & \emph{fastest} \\
      \hline
    \end{tabular}
  }
\end{frame}

\begin{frame}
  \frametitle{The Penn Treebank tagset (2)}
  {\footnotesize
    \begin{tabular}{|lll|lll|}
      \hline
      RP & Particle & \emph{up,off} &
      WP\$ & Possessive-Wh & \emph{whose} \\ 
      SYM & Symbol & \emph{+,\%,\&}  &
      WRB & Wh-adverb & \emph{how,where} \\
      TO & ``to'' & \emph{to} &
      \$ & Dollar sign & \emph{\$}\\
      UH & Interjection & \emph{oh, oops} &
      \# & Pound sign & \emph{\#} \\
      VB & verb, base form &     \emph{eat} &
      `` & Left quote & ` , `` \\
      VBD & verb, past tense & \emph{ate} &
      '' & Right quote & ', '' \\
      VBG & verb, gerund & \emph{eating} &
      ( & Left paren & ( \\
      VBN & verb, past part & \emph{eaten} &
      ) & Right paren & ) \\
      VBP & Verb, non-3sg, pres & \emph{eat} &
      , & Comma & , \\
      VBZ & Verb, 3sg, pres & \emph{eats} &
      . & Sent-final punct & . ! ? \\
      WDT & Wh-determiner &  \emph{which,that} &
      : & Mid-sent punct. & : ; --- ... \\
      WP & Wh-pronoun & \emph{what,who} & & & \\
      \hline
    \end{tabular}
  }
\end{frame}

\section{PoS Tagging in NLTK}

\subsection{Tagging}

\begin{frame}
   \mode<presentation>{\frametitle{Tagging}}
  \begin{itemize}
  \item Definition: Tagging is the assignment of a single
    part-of-speech tag to each word (and punctuation marker) in a
    corpus.  For example:\\
    {\scriptsize
    \textcolor{black}{``/``  The/DT  guys/NNS  that/WDT  make/VBP
      traditional/JJ  hardware/NN  are/VBP  really/RB  being/VBG
      obsoleted/VBN  by/IN  microprocessor-based/JJ  machines/NNS  ,/,
      ''/''  said/VBD  Mr./NNP  Benton/NNP  ./.}}
  \item Non-trivial: POS tagging must resolve ambiguities since the
    same word can have different tags in different contexts
  \item In the Brown corpus 11.5\% of word types and 40\% of word
    tokens are ambiguous
  \item In many cases one tag is much more likely for a given word
    than any other
  \item Limited scope: only supplying a tag for each word, no larger
    structures created (eg prepositional phrase attachment)
  \end{itemize}  
\end{frame}

%There                  EX
%are                    VBP
%11                     CD
%players                        NNS
%in                     IN
%a                      DT
%football               NN
%team                   NN
%.                      .

\begin{frame}
  \frametitle{Information sources for tagging}

  What information can help decide the correct PoS tag for a word?
  \begin{description}
  \item[Other PoS tags] Even though the PoS tags of other words may be
    uncertain too, we can use information that some tag sequences are
    more likely than others (eg \emph{the/AT red/JJ drink/NN} vs \emph{the/AT
      red/JJ drink/VBP}).\newline
    Using \emph{only} information about the most likely PoS tag
    sequence does not result in an accurate tagger (about 77\%
    correct)
  \item[The word identity] Many words can gave multiple possible tags,
    but some are more likely than others (eg \emph{fall/VBP} vs
    \emph{fall/NN}) \newline
    Tagging each word with its most common tag results in a tagger
    with about 90\% accuracy
  \end{description}
\end{frame}


\subsection{Simple taggers} 

%%% Assume Ewan will introduce the idea of a tagged token being a double

\begin{frame}[fragile]
  \frametitle{Tagging in NLTK}
The simplest possible tagger tags everything as a noun:
{\small
\begin{verbatim}
from nltk_lite import tokenize
text = 'There are 11 players in a football team'
text_tokens = list(tokenize.whitespace(text))
# ['There', 'are', '11', 'players', 'in', 'a', 'football', 'team']
\end{verbatim}
  \pause
\begin{verbatim}
from nltk_lite import tag
mytagger = tag.Default('nn')
for t in mytagger.tag(text_tokens):
    print t
# ('There', 'NN')
# ('are', 'NN')
# ...
\end{verbatim}}
\end{frame}

\begin{frame}[fragile]
  \frametitle{A regular expression tagger}
We can use regular expressions to tag tokens based on regularities in
the text, eg numerals:

{\small
\begin{verbatim}
default_pattern = (r'.*', 'NN')
cd_pattern = (r' ^[0-9]+(.[0-9]+)?$', 'CD')
patterns = [cd_pattern, default_pattern]
NN_CD_tagger = tag.Regexp(patterns)
re_tagged = list(NN_CD_tagger.tag(text_tokens))
# [('There', 'NN'), ('are', 'NN'), ('11', 'NN'), ('players', 'NN'), 
('in', 'NN'), ('a', 'NN'), ('football', 'NN'), ('team', 'NN')]
\end{verbatim}
}%$
\end{frame}



\subsection{Unigram taggers} 

\begin{frame}[fragile]
  \frametitle{A unigram tagger}
The NLTK UnigramTagger class implements a tagging algorithm based on a
table of unigram probabilities:
\[ \mbox{tag}(w) = \arg\max_{t_i} P(t_i|w) \]

\pause
Training a UnigramTagger on the Penn Treebank:
{\small
\begin{verbatim}
from nltk_lite.corpora import treebank
from itertools import islice

# sentences 0-2999
train_sents = list(islice(treebank.tagged(), 3000))
# from sentence 3000 to the end
test_sents = list(islice(treebank.tagged(), 3000, None))

unigram_tagger = tag.Unigram()
unigram_tagger.train(train_sents)
\end{verbatim}}
\end{frame}



\begin{frame}[fragile]
  \frametitle{Unigram tagging}
{\small
\begin{verbatim}
>>> list(unigram_tagger.tag(tokenize.whitespace("Mr. Jones saw 
the book on the shelf")))
[('Mr.', 'NNP'), ('Jones', 'NNP'), ('saw', 'VBD'), ('the', 'DT'), 
('book', 'NN'), ('on', 'IN'), ('the', 'DT'), ('shelf', None)]
\end{verbatim}}

  The UnigramTagger assigns the default tag \texttt{None} to words
  that are not in the training data (eg \emph{shelf})

  \pause
  We can combine taggers to ensure every word is tagged:
{\small
\begin{verbatim}
>>> unigram_tagger = tag.Unigram(cutoff=0,backoff=NN_CD_tagger)
>>> unigram_tagger.train(train_sents)
>>> list(unigram_tagger.tag(tokenize.whitespace("Mr. Jones saw 
the book on the shelf")))
[('Mr.', 'NNP'), ('Jones', 'NNP'), ('saw', 'VBD'), ('the', 'DT'), 
('book', 'VB'), ('on', 'IN'), ('the', 'DT'), ('shelf', 'NN')]
\end{verbatim}}
\end{frame}



\section{Evaluating taggers}

\subsection{Accuracy and gold standard} 

\begin{frame}
  \frametitle{Evaluating taggers}
  \begin{itemize}
  \item Basic idea: compare the output of a tagger with a
    human-labelled \emph{gold standard}
  \item Need to compare how well an automatic method does with the
    agreement between people
  \item The best automatic methods have an accuracy of about 96-97\%
    when using the (small) Penn treebank tagset (but this is still an
    average of one error every couple of sentences...)
  \item Inter-annotator agreement is also only about 97\% 
  \item A good unigram baseline (with smoothing) can obtain 90-91\%!
  \end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Evaluating taggers in NLTK}
  NLTK provides a function \texttt{tag.accuracy} to automate
  evaluation.  It needs to be provided with a tagger, together with
  some text to be tagged and the gold standard tags.  
  
  \pause
  We can make
  print more prettily:
\begin{verbatim}
def print_accuracy(tagger, data):
    print '%3.1f%%' % (100 * tag.accuracy(tagger, data))
\end{verbatim}

  \pause
\begin{verbatim}
>>> print_accuracy(NN_CD_tagger, test_sents)
15.0%
>>> print_accuracy(unigram_tagger, train_sents)
93.8%
>>> print_accuracy(unigram_tagger, test_sents)
82.8%
\end{verbatim}
\end{frame}

\subsection{Error analysis} 

\begin{frame}
   \mode<presentation>{\frametitle{Error analysis}}
  \begin{itemize}
  \item The \% correct score doesn't tell you everything --- it is
    useful know what is misclassified as what
  \item \emph{Confusion matrix}: A matrix (ntags x ntags) where the rows
    correspond to the correct tags and the columns correspond to the
    tagger output.  Cell $(i,j)$ gives the count of the number of
    times tag $i$ was classified as tag $j$
  \item The leading diagonal elements correspond to correct
    classifications
  \item Off diagonal elements correspond to misclassifications 
  \item Thus a confusion matrix gives information on the major
    problems facing a tagger (eg NNP vs. NN vs. JJ)
  \item See section 3 of the NLTK tutorial on Tagging
  \end{itemize}
\end{frame}

\section{Summary}

\begin{frame}
  \mode<presentation>{\frametitle{Summary}}
  \begin{itemize}
    \item \textbf{Reading:} Chapter 8 of Jurafsky and Martin
    \item Parts of speech and tagsets
    \item Tagging
    \item Constructing simple taggers in NLTK
    \item Evaluating taggers
    \item Next lecture: n-grams
  \end{itemize}
\end{frame}

\end{document}
