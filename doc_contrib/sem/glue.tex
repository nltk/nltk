\documentclass{article}

\usepackage{geometry}
\geometry{hmargin={1in,1in}, vmargin={1in, 1in}}

\usepackage{natbib}
\bibpunct{[}{]}{;}{a}{,}{,}
\bibliographystyle{alpha}

\usepackage{covington}
\usepackage{amssymb}
\usepackage{bussproofs}
\usepackage{datetime}
\input avm.sty

%\usepackage[colorlinks]{hyperref}
\usepackage[pdftex,colorlinks=true,
                      pdfstartview=FitV,
                      linkcolor=blue,
                      citecolor=blue,
                      urlcolor=blue
          ]{hyperref}

\pdfinfo{
   /Author 			(Daniel H. Garrette)
   /Title  			(NLTK: Glue Semantics)
   /CreationDate 	(D:\pdfdate)
   /Subject 		(Glue Semantics)
   /Keywords 		(Natural Language Processing;Computational Semantics;Glue 
					   Semantics)
}

\begin{document}

\section{Glue Semantics}

Files associated with this chapter (to be placed in the `ntlk\_lite/semantics'
directory): 

\begin{itemize}
  \item \url{http://www.iwu.edu/~dgarrett/programming/ntlk/glue/glue.py}
  \item \url{http://www.iwu.edu/~dgarrett/programming/ntlk/glue/linearlogic.py}
  \item \url{http://www.iwu.edu/~dgarrett/programming/ntlk/glue/grammar.cfg}
  \item \url{http://www.iwu.edu/~dgarrett/programming/ntlk/glue/glue.cfg}
\end{itemize}


\subsection{Introduction}
This chapter expands on the ideas about Semantic Interpretation presented in
Chapter 11.  The \textbf{Principle of Compositionality} states that the meaning
of a whole is a function of the meanings of the parts and of the way they are
syntactically combined. Chapter 11 described an algorithm to perform this
composition.  However, as it was noted in the chapter, there are some
limitations that quickly arise.  For example, note (43), (44a), and (44b) from
Chapter 11 repeated here as (\ref{ex1})--(\ref{ex3}) respectively.

\begin{examples}
	\item\label{ex1} Every girl chases a dog.
	\item\label{ex2} all x.((girl x) implies some y. ((dog y) and (chase x y)))
	\item\label{ex3} some y.((dog y) and all x. ((girl x) implies (chase x y)))
\end{examples}

In this example, (\ref{ex1}) should give rise to both readings (\ref{ex2}) and
(\ref{ex3}). However, the procedure described in Chapter 11 only generates
(\ref{ex2}). The reason for this discrepancy is that semantic interpretation in
Chapter 11 is too closely tied to syntax. In sentence (\ref{ex2}), the word
``every'' out-scopes the word ``a''. This is a result of the sentence's word
order: ``every'' comes before ``a''. In the semantic composition, ``every''
combines with ``boy'' and ``a'' with ``girl''. But since ``a girl'' is a
sub-part of the VP ``chases a girl'', ``a girl'' is combined with ``chases''
before ``every boy'' is.

In contrast, the topic of this chapter, Glue Semantics, offers an elegant
approach to determining scope based on the use of resource-sensitive logic as a
means to ``glue'' the $\lambda$-calculus meaning terms together.

\subsection{Linear Logic}
The particular "glue" logic that we will use is \textbf{Implicational Linear
Logic}. It is a subset of Propositional Logic (see Chapter 11.3). The logic is
``implicational'' because it's only operator is the implication. However, we will
use the symbol `$\multimap$' for linear logic implication instead of the symbol
`$\rightarrow$' which was used in the propositional and first order logics. Just as
in propositional logic, the implication is used in the following way:

\begin{examples}
	\item\label{ex4} A, (A $\multimap$ B) $\vdash$ B
\end{examples}

Linear Logic is \textbf{resource-sensitive} because every premise in a
resource-sensitive proof must be used \underline{once and only once}. Therefore,
unlike propositional or first order logics, we have the following rules:
	
\begin{examples}
	\item\label{ex5} A, (A $\multimap$ B) $\nvdash$ A, B
	\item\label{ex6} A, A, (A $\multimap$ B) $\nvdash$ B
\end{examples}

The best way to think about these rules is consider the linear logic
implicational statement as a function that \textbf{consumes} its antecedent and
itself to \textbf{produce} its consequent.  Example (\ref{ex4}) is valid because A
is applied to (A $\multimap$ B) which consumes both and produces B.  On the
other hand (\ref{ex5}) is \underline{invalid} because the premise A is consumed
by the implication and therefore cannot appear in the conclusion.  Finally,
(\ref{ex6}) is \underline{invalid} because the premise A appears twice, but
there is only one implication to consume it, and since every premise must be
used exactly once, the second instance of A cannot be ignored.

\subsubsection{Linear Logic in NLTK}
All the tools needed to work in implicational linear logic are found in the file
``linearlogic.py", which should be placed in the ``semantics" folder.  This
module is modeled after the module logic.py.  Strings can be parsed using the
class Parser; ApplicationExpressions can be applied to other Expressions
using the method applyto().  Note that applyto() will only succeed if the
application is legal, otherwise it will raise an exception.

\begin{tabular}{|l|}
%{\fontfamily{courier}\selectfont Testing testing testing}
\hline
\textgreater\textgreater\textgreater from nltk\_lite.semantics import linearlogic \cr
\textgreater\textgreater\textgreater llp = linearlogic.Parser() \cr
\textgreater\textgreater\textgreater p = llp.parse(`p') \cr
\textgreater\textgreater\textgreater print p \cr
p \cr
\textgreater\textgreater\textgreater p\_q = llp.parse(`(p -o q)') \cr
\textgreater\textgreater\textgreater print p\_q \cr
(-o p q) \cr
\textgreater\textgreater\textgreater print p\_q.infixify() \cr
(p -o q) \cr
\textgreater\textgreater\textgreater q = p\_q.applyto(p) \cr
\textgreater\textgreater\textgreater q \cr
ApplicationExpression(`(-o p q)', `p') [] \cr
\textgreater\textgreater\textgreater print q.simplify().infixify() \cr
q \cr
\textgreater\textgreater\textgreater p = p\_q.applyto(q) \cr
LinearLogicApplicationError: Attempting to apply (-o p q) to q \cr
\hline
\end{tabular} 

The module also binds variables correctly and stores those bindings for
future applications.  The when printing an Expression, the bindings are
displayed as a list at the end.

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater gf = llp.parse(`(g -o f)') \cr
\textgreater\textgreater\textgreater gGG = llp.parse(`((g -o G) -o G)') \cr
\textgreater\textgreater\textgreater f = gGG.applyto(gf) \cr
\textgreater\textgreater\textgreater f \cr
ApplicationExpression(`(-o (-o g G) G)', `(-o g f)') [(G, f)] \cr
\textgreater\textgreater\textgreater print f.simplify().infixify() \cr
f \cr
\textgreater\textgreater\textgreater HHG = llp.parse(`(H -o (H -o G))') \cr
\textgreater\textgreater\textgreater ff = HHG.applyto(f) \cr
\textgreater\textgreater\textgreater print ff \cr
(-o H (-o H G) (-o (-o g G) G (-o g f)) [(G, f)]) [(G, f), (H, f)] \cr
\textgreater\textgreater\textgreater print ff.simplify().infixify() \cr
(f -o f) \cr
\hline
\end{tabular}

\subsection{Glue Formulas}
In chapter 11, we introduced the idea that words can be associated with meaning
terms stated in $\lambda$-calculus.  For example, the verb `walk' can be
represented as a function from a value of type \textbf{Ind} to a value of type
\textbf{Bool}, $\lambda$x.walk(x). Glue semantics extends this system by
dictating that a Glue Formula is comprised of a meaning term and a ``Glue Term''. 
The Glue Term is a linear logic statement that constrains the ways that the Glue
Formula may combine with other glue formulas. For the verb ``walks'', the glue
statement would be `(g $\multimap$ f)' where `g' represents the verb's subject
(an Ind) and `f' represents the verb's clause.  Thus the Glue Formula for the
verb `walk' is a pair `$\lambda$x.(walk x) : (g $\multimap$ f)'.
	
To show how this Glue Formula is used, let us assume that a proper noun, such as
`John', is represented with the Glue Formula `John : g' since John is of the
type \textbf{Ind}. If we want to combine these formulas to get the meaning of
the sentence ``John walks'' we will do so by allowing the glue terms to dictate
how the meaning terms will be applied. The glue terms can be combined as a proof
of `f', which represents the entire sentence. This is shown as (\ref{ex7}):

\begin{examples}
	\item\label{ex7} g, (g $\multimap$ f) $\vdash$ f
\end{examples}

In order to produce the reading for the sentence from this linear logic proof,
we will have to attach the meaning terms to the glue terms and apply them
appropriately at each step of the proof.  The rule for applying one glue formula
to another is shown in (\ref{ex8}):

\begin{examples}
	\item\label{ex8} \begin{prooftree}
						\AxiomC{$\phi$ : A}
						\AxiomC{$\psi$ : (A $\multimap$ B)}
						\BinaryInfC{$\psi$($\phi$) : B}
					 \end{prooftree}
\end{examples}

Therefore, all together we have the following proof that produces a semantic
meaning for the sentence ``John walks'' in (\ref{ex9}):

\begin{examples}
	\item\label{ex9} \begin{prooftree}
						\AxiomC{John : g}
						\AxiomC{$\lambda$$x$.(walks $x$) : (g $\multimap$ f)}
						\BinaryInfC{$\lambda$$x$.(walks $x$)(John) : f}
					 \end{prooftree}
\end{examples}

And `$\lambda$$x$.(walks $x$)(John)' $\beta$-reduces to `(walk John)'.


\subsubsection{Glue Formulas in NLTK}

The tools available for using Glue Semantics are found in the file ``glue.py''. 
The GlueFormula class is used for glue formulas.  It contains an appyto() method
for performing applications on other GlueFormulas.

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater from nltk\_lite.semantics import glue \cr
\textgreater\textgreater\textgreater walks =
glue.GlueFormula(`\textbackslash\textbackslash x.(walks x)', `(g -o f)') \cr 
\textgreater\textgreater\textgreater walks \cr
\textbackslash x.(walks x) : (-o g f) \cr
\textgreater\textgreater\textgreater john = glue.GlueFormula(`John', `g') \cr
\textgreater\textgreater\textgreater john \cr
John : g \cr
\textgreater\textgreater\textgreater john\_walks = walks.applyto(john) \cr
\textgreater\textgreater\textgreater john\_walks \cr
(\textbackslash x.(walks x) John) : (-o g f g) \cr
\textgreater\textgreater\textgreater john\_walks.simplify() \cr
(walks John) : f \cr
\hline
\end{tabular}


\subsection{Syntax-Semantics Interface}
An appropriate next question would ask how we determine which propositions
to use in the glue terms.  For example, in (\ref{ex9}), why is `John' paired
with `g' and `walks' with `(g $\multimap$ f)'? The answer is that `walks' is an
intransitive verb and the meaning of an intransitive verb is a function that
takes the verb's subject as input and returns the truth value of the verb's
clause.  In our example, `g' is the proposition representing the verb's subject,
so it is natural that it is the antecedent in the verb's glue term.
	
The traditional way that syntactic relationships are shown in Glue literature is
with Lexical Functional Grammar \citep{Dalrymple2001}.  The sentence
``John walks'' would be represented as (\ref{ex10}):

\begin{examples}
	\item\label{ex10} \begin{avm}
                      	f:\[PRED & `walks\q<SUBJ\q>' \cr
                      		SUBJ & g:\[ PRED & `John'\]
                       	\]
                      \end{avm}
\end{examples}

This style of marking syntactic structure allows us to clearly see that `f'
represented the entire sentence and that `g' represents the subject of the
sentence. Let us compare this to the representation and subsequent proof (with
$\beta$-reductions done as we progress) of the sentence ``John sees Mary'',
shown as (\ref{ex11}) and (\ref{ex12}) respectively:
		
\begin{examples}
	\item\label{ex11} 
		\begin{avm}
	      	f:\[PRED & `walks\q<SUBJ, OBJ\q>' \cr
	      		SUBJ & g:\[ PRED & `John'\] \cr
	      		OBJ  & h:\[ PRED & `Mary'\]
	       	\]
		\end{avm}

	\item\label{ex12} 
		\begin{prooftree}
			\AxiomC{Mary : h}
			\AxiomC{John : g}
			\AxiomC{$\lambda$$x$.$\lambda$$y$.(see $x$ $y$) : (g $\multimap$ (h $\multimap$ f))}
			\BinaryInfC{$\lambda$$y$.(see John $y$) : (h $\multimap$ f)}
			\BinaryInfC{(see John Mary) : f}
		\end{prooftree}
\end{examples}

In this case the verb is transitive, so it must have a subject (`John') and an
object (`Mary'). 

\subsubsection{Transitive Verbs in NLTK}

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater from nltk\_lite.semantics import glue \cr
\textgreater\textgreater\textgreater john = glue.GlueFormula(`John', `g') \cr
\textgreater\textgreater\textgreater mary = glue.GlueFormula(`Mary', `h') \cr
\textgreater\textgreater\textgreater sees = glue.GlueFormula(`\textbackslash\textbackslash x y.(sees x y)', `(g
-o (h -o f))') \cr
\textgreater\textgreater\textgreater john\_sees =
sees.applyto(john) \cr
\textgreater\textgreater\textgreater john\_sees.simplify().infixify() \cr
\textbackslash y.(sees John y) : (h -o f) \cr
\textgreater\textgreater\textgreater john\_sees\_mary =
john\_sees.applyto(mary) \cr
\textgreater\textgreater\textgreater john\_sees\_mary.simplify().infixify() \cr
(sees John Mary) : f \cr
\hline
\end{tabular}

Also, notice what happens if we try to apply the individuals in the wrong
sequence: 

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater sees.applyto(mary) \cr
LinearLogicApplicationError: \textbackslash x y.(sees x y) : (-o g (-o h f))
applied to Mary : h \cr
\hline
\end{tabular}

\subsection{Quantification}
As was noted in chapter 11, a quantifier is of type `((\textbf{Ind} $\rightarrow$
\textbf{Bool}) $\rightarrow$ ((\textbf{Ind} $\rightarrow$ \textbf{Bool})
$\rightarrow$ \textbf{Bool}))'.  A quantifier can combine with a noun, which is
of type `\textbf{Ind} $\rightarrow$ \textbf{Bool}', to give a quantified noun, 
which is of type `((\textbf{Ind} $\rightarrow$ \textbf{Bool}) $\rightarrow$
\textbf{Bool})'.  A quantified noun can then be combined with a
verb to make a clause.

For reference, let us give the LFG f-structure for the sentence ``a man walks'':
\begin{examples}
	\item\label{ex16} \begin{avm}
                      	f:\[PRED & `walks\q<SUBJ\q>' \cr
                      		SUBJ & g:\[ PRED & `man' \cr
                      					SPEC & `a'\]
                      	\]
                      \end{avm}
\end{examples}

We will examine the noun first.  The meaning of a noun can be viewed as a
function from an individual to a truth value.  For example, the glue formula for
the word ``man'' is given in (\ref{ex13}):

\begin{examples}
	\item\label{ex13} $\lambda$$x$.(man $x$) : (gv $\multimap$ gr)
\end{examples}

The meaning term tells us that ``man'' is a function that takes an individual as
input and returns a truth value for whether that individual is a man. The glue
term naturally mirrors the single-argument-function pattern of the meaning term.
Here we have $gv$, which is $g$'s VAR-value, and $gr$, which is $g$'s 
RESTR-value.  We can see in (\ref{ex17}) how a noun combines with a quantifier
to create a quantified noun phrase.

\begin{examples}
	\item\label{ex17} \begin{prooftree}
			\AxiomC{$\lambda$$x$.(man $x$) : (gv $\multimap$ gr)}
			\AxiomC{$\lambda$$P$.$\lambda$$Q$.some $x$.(($P$ $x$) and ($Q$ $x$)) : ((gv
					$\multimap$ gr) $\rightarrow$ ((g $\multimap$ G) $\multimap$ G))}
			\BinaryInfC{$\lambda$$Q$.some $x$.(($man$ $x$) and ($Q$ $x$)) : ((g
						$\multimap$ G) $\multimap$ G)}
		\end{prooftree}
\end{examples}

At this point we must pause to discuss the glue proposition `G'.  In the glue
for this quantified noun phrase, `G' is a variable\footnote{We will always use
capital letters to distinguish linear logic variables.} standing for an
expression of type \textbf{Bool}. As one would expect from a variable, it may
bind with any proposition of type \textbf{Bool} in the course of a proof. We can
now see how the result from (\ref{ex17}) can be combined with the word
``walks'' to give the reading of the entire sentence.  The proof is given in
(\ref{ex18}).

\begin{examples}
	\item\label{ex18} 
		\begin{prooftree}
			\AxiomC{$\lambda$$x$.(walks $x$) : (g $\multimap$ f)}
			\AxiomC{$\lambda$$Q$.some $x$.(($man$ $x$) and ($Q$ $x$)) : ((g
						$\multimap$ G) $\multimap$ G)}
			\BinaryInfC{some $x$.(($man$ $x$) and ($walks$ $x$)) : f}
		\end{prooftree}
\end{examples}

An existential quantifier such as ``a" or ``some" is represented as
(\ref{ex14}).  A universal quantifier such as ``all'' or ``every'' is
represented as (\ref{ex15}).

\begin{examples}
	\item\label{ex14} $\lambda$$P$.$\lambda$$Q$.some $x$.(($P$ $x$) and ($Q$ $x$))
		: ((gv $\multimap$ gr) $\multimap$ ((g $\multimap$ G) $\multimap$ G))
	\item\label{ex15} $\lambda$$P$.$\lambda$$Q$.all $x$.(($P$ $x$) 
		implies ($Q$ $x$)) : ((gv $\multimap$ gr) $\multimap$ ((g
		$\multimap$ G) $\multimap$ G))
\end{examples}

\subsubsection{Quantification in NLTK}

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater a = glue.GlueFormula(`\textbackslash\textbackslash P Q.some x.((P x) and (Q x))', `((gv -o
gr) -o ((g -o G) -o G))')  \cr
\textgreater\textgreater\textgreater man = glue.GlueFormula(`\textbackslash\textbackslash x.(man x)', `(gv -o
gr)') \cr 
\textgreater\textgreater\textgreater walks = glue.GlueFormula(`\textbackslash\textbackslash x.(walks x)', `(g -o
f)') \cr 
\textgreater\textgreater\textgreater a\_man = a.applyto(man) \cr
\textgreater\textgreater\textgreater print a\_man.simplify().infixify() \cr
\textbackslash Q.some x.((man x) and (Q x)) : ((g -o G) -o G) \cr
\textgreater\textgreater\textgreater a\_man\_walks = a\_man.applyto(walks) \cr
\textgreater\textgreater\textgreater print a\_man\_walks.simplify().infixify() \cr
some x.((man x) and (walks x)) : f \cr
\hline
\end{tabular}


\subsection{Semantic Ambiguity}
Semantic ambiguity is ambiguity that arises from semantics, even when the
syntax is unambiguous.  An example of a semantically ambiguous sentence is
(\ref{ex1}), repeated here as (\ref{ex19}).  It is ambiguous because it can be
interpreted as either (\ref{ex20}) or (\ref{ex21}).

\begin{examples}
	\item\label{ex19} Every girl chases a dog.
	\item\label{ex20} all x.((girl x) implies some y. ((dog y) and (chase x y)))
	\item\label{ex21} some y.((dog y) and all x. ((girl x) implies (chase x y)))
\end{examples}

Glue semantics will allow us to generate both of these readings through the same
proof strategies.  But first, we will have to introduce a new proof rule. 
The rule in (\ref{ex22}) allows us to create a unique\footnote{The index
$i$ in the proof must always be fresh to ensure uniqueness}
temporary hypothesis and then to abstract it away.

\begin{examples}
	\item\label{ex22}
		\begin{prooftree}
			\AxiomC{$x$ : [A]$_i$}
			\noLine
			\UnaryInfC{$\vdots$}
			\noLine
			\UnaryInfC{$\psi$ : B}
			\RightLabel{\scriptsize{ABS$_i$}}
			\UnaryInfC{$\lambda$$x$.$\psi$ : (A $\multimap$ B)}
		\end{prooftree}
\end{examples}

So, to generate readings for (\ref{ex19}), we start with a list of premises:

\begin{examples}
	\item\label{ex23} \textbf{[every]} $\lambda$$P$.$\lambda$$Q$.all $x$.(($P$ $x$) 
		implies ($Q$ $x$)) : ((gv $\multimap$ gr) $\multimap$ ((g
		$\multimap$ G) $\multimap$ G))
	\item\label{ex24} \textbf{[girl]} $\lambda$$x$.(girl $x$) : (gv $\multimap$ gr)
	\item\label{ex25} \textbf{[chases]} $\lambda$$x$.$\lambda$$y$.(chases $x$ $y$) :
		(g $\multimap$ (h $\multimap$ f))
	\item\label{ex26} \textbf{[a]} $\lambda$$P$.$\lambda$$Q$.some $x$.(($P$ $x$)
		and ($Q$ $x$)) : ((hv $\multimap$ hr) $\multimap$ ((h $\multimap$ H)
		$\multimap$ H))
	\item\label{ex27} \textbf{[dog]} $\lambda$$x$.(dog $x$) : (hv $\multimap$ hr)
\end{examples}

It is easy to see that ``every'' can only combine with ``girl'' and ``a'' only
with ``dog''.  We perform these combinations to generate both quantified nouns.

\begin{examples}
	\item\label{ex28} \textbf{[every-girl]} $\lambda$$Q$.all $x$.((girl $x$) 
		implies ($Q$ $x$)) : ((g $\multimap$ G) $\multimap$ G)
	\item\label{ex29} \textbf{[a-dog]} $\lambda$$Q$.some $x$.((dog $x$)
		and ($Q$ $x$)) : ((h $\multimap$ H) $\multimap$ H)
\end{examples}

Now we can generate exactly two readings from these two quantified nouns and the
verb ``chases''.  The proofs are detailed as (\ref{ex30}) and (\ref{ex31}):

\begin{tiny}
\begin{examples}
	\item\label{ex30}
		\begin{prooftree}
			\AxiomC{$x^1$ : [g]$_1$}
			\AxiomC{$\lambda$$x$.$\lambda$$y$.(chases $x$ $y$) : (g $\multimap$ (h
				$\multimap$ f))} 
			\BinaryInfC{$\lambda$$y$.(chases $x^1$ $y$) : (h $\multimap$ f)}
			\AxiomC{$\lambda$$Q$.some $x$.((dog $x$) and ($Q$ $x$)) : ((h $\multimap$ H)
				$\multimap$ H)}
			\BinaryInfC{some $x$.((dog $x$) and (chases $x^1$ $x$)) : f}
			\RightLabel{\tiny{ABS$_1$}}
			\UnaryInfC{$\lambda$$x^1$.some $x$.((dog $x$) and (chases $x^1$ $x$)) : (g
				$\multimap$ f)}
			\AxiomC{$\lambda$$Q$.all $x$.((girl $x$) implies ($Q$ $x$)) : ((g
				$\multimap$ G) $\multimap$ G)} 
			\BinaryInfC{all $x$.((girl $x$) implies (some $z^1$.((dog $z^1$) and (chases $x$ $z^1$)))) : f}
		\end{prooftree}

	\item\label{ex31}
		\begin{prooftree}
			\AxiomC{$x^2$ : [h]$_2$}
			\AxiomC{$x^1$ : [g]$_1$}
			\AxiomC{$\lambda$$x$.$\lambda$$y$.(chases $x$ $y$) : (g $\multimap$ (h
				$\multimap$ f))} 
			\BinaryInfC{$\lambda$$y$.(chases $x^1$ $y$) : (h $\multimap$ f)}
			\BinaryInfC{(chases $x^1$ $x^2$) : f}
			\RightLabel{\tiny{ABS$_1$}}
			\UnaryInfC{$\lambda$$x^1$.(chases $x^1$ $x^2$) : (g
				$\multimap$ f)}
			\AxiomC{$\lambda$$Q$.all $x$.((girl $x$) implies ($Q$ $x$)) : ((g
				$\multimap$ G) $\multimap$ G)} 
			\BinaryInfC{all $x$.((girl $x$) implies (chases $x$ $x^2$)) : f}
			\RightLabel{\tiny{ABS$_2$}}
			\UnaryInfC{$\lambda$$x^2$.all $x$.((girl $x$) implies (chases $x$ $x^2$)) : (h
				$\multimap$ f)}
			\AxiomC{$\lambda$$Q$.some $x$.((dog $x$) and ($Q$ $x$)) : ((h $\multimap$ H)
				$\multimap$ H)}
			\BinaryInfC{some $x$.((dog $x$) and (all $z^1$.((girl $z^1$) implies (chases $z^1$ $x$)))) : f}
		\end{prooftree}
\end{examples}
\end{tiny}

\subsubsection{Semantic Ambiguity in NLTK}

To generate the readings of the sentence ``Every girl chases a dog'', we must
generate the quantified noun phrases `every girl' and `a dog' first, along with
the verb `chases'.

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater every = glue.GlueFormula('\textbackslash\textbackslash P Q.all x.((P x) implies (Q x))',
'((gv -o gr) -o ((g -o G) -o G))') \cr
\textgreater\textgreater\textgreater girl = glue.GlueFormula('\textbackslash\textbackslash x.(girl x)', '(gv -o
gr)') \cr
\textgreater\textgreater\textgreater every\_girl = every.applyto(girl) \cr
\textgreater\textgreater\textgreater print every\_girl.simplify().infixify() \cr
\textbackslash Q.all x.((girl x) implies (Q x)) : ((g -o G) -o G) \cr
\textgreater\textgreater\textgreater chases =
glue.GlueFormula('\textbackslash\textbackslash x y.(chases x y)', '(g -o (h -o f))') \cr
\textgreater\textgreater\textgreater print chases.infixify() \cr
\textbackslash x y.(chases x y) : (g -o (h -o f)) \cr
\textgreater\textgreater\textgreater a = glue.GlueFormula('\textbackslash\textbackslash P Q.some x.((P x) and (Q x))', '((hv -o
hr) -o ((h -o H) -o H))') \cr
\textgreater\textgreater\textgreater dog = glue.GlueFormula('\textbackslash\textbackslash x.(dog x)', '(hv -o
hr)') \cr
\textgreater\textgreater\textgreater a\_dog = a.applyto(dog) \cr
\textgreater\textgreater\textgreater print a\_dog.simplify().infixify() \cr
\textbackslash Q.some x.((dog x) and (Q x)) : ((h -o H) -o H) \cr
\hline
\end{tabular}

Because the rest of the assembly requires the abstraction rule (\ref{ex22}), we will
need a new technique to achieve the functionality of this rule.  We will do this
by creating a hypothesis glue formula whose meaning term is a variable and whose
glue term is the glue expression needed.  We can then abstract this hypothesis
away using the method lambda\_abstract() which takes the hypothesis to be
abstracted as its argument.

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater x1 = glue.GlueFormula('x1', 'A') \cr
\textgreater\textgreater\textgreater psi = glue.GlueFormula('\textbackslash\textbackslash x.(psi x)', '(A -o B)')
\cr 
\textgreater\textgreater\textgreater psi\_x1 = psi.applyto(x1) \cr
\textgreater\textgreater\textgreater print psi\_x1.simplify() \cr
(psi x1) : B \cr
\textgreater\textgreater\textgreater psi2 = psi\_x1.lambda\_abstract(x1) \cr
\textgreater\textgreater\textgreater print psi2 \cr
\textbackslash x1.(\textbackslash x.(psi x) x1) : (-o A (-o A B A)) \cr
\textgreater\textgreater\textgreater print psi2.simplify() \cr
\textbackslash x1.(psi x1) : (-o A B) \cr
\hline
\end{tabular}

We can now use this technique to generate the readings for ``Every girl chases
a dog'' from the quantified nouns and the verb.  The first will be modeled after
(\ref{ex30}):

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater x1 = glue.GlueFormula('x1', 'g') \cr
\textgreater\textgreater\textgreater x1\_chases = chases.applyto(x1) \cr
\textgreater\textgreater\textgreater print x1\_chases.simplify().infixify() \cr
\textbackslash y.(chases x1 y) : (h -o f) \cr
\textgreater\textgreater\textgreater x1\_chases\_a\_dog = a\_dog.applyto(x1\_chases) \cr
\textgreater\textgreater\textgreater print x1\_chases\_a\_dog.simplify().infixify() \cr
some x.((dog x) and (chases x1 x)) : f \cr
\textgreater\textgreater\textgreater chases\_a\_dog = x1\_chases\_a\_dog.lambda\_abstract(x1) \cr
\textgreater\textgreater\textgreater print chases\_a\_dog.simplify().infixify() \cr
\textbackslash x1.some x.((dog x) and (chases x1 x)) : (g -o f) \cr
\textgreater\textgreater\textgreater every\_girl\_chases\_a\_dog = every\_girl.applyto(chases\_a\_dog) \cr
\textgreater\textgreater\textgreater print every\_girl\_chases\_a\_dog.simplify().infixify() \cr
all x.((girl x) implies some z1.((dog z1) and (chases x z1))) : f \cr
\hline
\end{tabular}

The second will be modeled after (\ref{ex31}):

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater x1 = glue.GlueFormula('x1', 'g') \cr
\textgreater\textgreater\textgreater x1\_chases = chases.applyto(x1) \cr
\textgreater\textgreater\textgreater print x1\_chases.simplify().infixify() \cr
\textbackslash y.(chases x1 y) : (h -o f) \cr
\textgreater\textgreater\textgreater x2 = glue.GlueFormula('x2', 'h') \cr
\textgreater\textgreater\textgreater x1\_chases\_x2 = x1\_chases.applyto(x2) \cr
\textgreater\textgreater\textgreater print x1\_chases\_x2.simplify().infixify() \cr
(chases x1 x2) : f \cr
\textgreater\textgreater\textgreater chases\_x2 = x1\_chases\_x2.lambda\_abstract(x1) \cr
\textgreater\textgreater\textgreater print chases\_x2.simplify().infixify() \cr
\textbackslash x1.(chases x1 x2) : (g -o f) \cr
\textgreater\textgreater\textgreater every\_girl\_chases\_x2 = every\_girl.applyto(chases\_x2) \cr
\textgreater\textgreater\textgreater print every\_girl\_chases\_x2.simplify().infixify() \cr
all x.((girl x) implies (chases x x2)) : f \cr
\textgreater\textgreater\textgreater every\_girl\_chases = every\_girl\_chases\_x2.lambda\_abstract(x2) \cr
\textgreater\textgreater\textgreater print every\_girl\_chases.simplify().infixify() \cr
\textbackslash x2.all x.((girl x) implies (chases x x2)) : (h -o f) \cr
\textgreater\textgreater\textgreater every\_girl\_chases\_a\_dog = a\_dog.applyto(every\_girl\_chases) \cr
\textgreater\textgreater\textgreater print every\_girl\_chases\_a\_dog.simplify().infixify() \cr
some x.((dog x) and all z1.((girl z1) implies (chases z1 x))) : f \cr
\hline
\end{tabular}

\subsection{Computational Issues in Glue Semantics}

\subsubsection{Generation of Glue Formulas}
To generate the glue formulas that will be used in the proof, we must first
parse the sentence for syntax (see Chapters 7 and 8).  The glue module includes
a class FStructure that is created from a parse tree.

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater from
nltk\_lite.parse import GrammarFile \cr
\textgreater\textgreater\textgreater from nltk\_lite
import tokenize \cr
\textgreater\textgreater\textgreater grammar =
GrammarFile.read\_file('grammar.cfg') \cr
\textgreater\textgreater\textgreater parsetrees =
grammar.earley\_parser(0).get\_parse\_list(list(tokenize.whitespace('John sees a woman')))
\cr 
\textgreater\textgreater\textgreater from
nltk\_lite.semantics import glue \cr
\textgreater\textgreater\textgreater glue\_dict =
glue.GlueDict() \cr
\textgreater\textgreater\textgreater
glue\_dict.read\_file('glue.cfg') \cr
\textgreater\textgreater\textgreater fstruct =
glue.FStructure(parsetrees[0][0], [0]) \cr
\textgreater\textgreater\textgreater print fstruct \cr
f:$[$pred 'sees' \cr
~~~subj g:$[$pred 'John'$]$ \cr
~~~obj h:$[$pred 'woman' \cr
~~~~~~~~~~spec 'a'$]]$ \cr
\textgreater\textgreater\textgreater for gf in fstruct.to\_glueformula\_list(glue\_dict): print gf \cr
\textbackslash x y.(sees x y) : (-o g (-o h f)) \cr
John : g \cr
\textbackslash x.(woman x) : (-o hv hr) \cr
\textbackslash P Q.some x.(and (P x) (Q x)) : (-o (-o hv hr) (-o (-o h H0) H0)) \cr
\hline
\end{tabular}

\subsubsection{Horn Clauses}
The problem of having the computer automatically assemble a sentence's glue
premises into a proof becomes much more difficult with the rule given in
(\ref{ex22}) because the rule opens up the possibility of an infinite number of
proofs for any valid set of premises.  This occurs because we are able to
introduce and retract hypotheses at will, whether they are required or not. 
So from the premises 'g' and '(g $\multimap$ f)' we can generate the following
proofs (\ref{ex32})-(\ref{ex34}): 

\begin{examples}
	\item\label{ex32}
		\begin{prooftree}
			\AxiomC{g}
			\AxiomC{(g $\multimap$ f)}
			\BinaryInfC{f}
		\end{prooftree}

	\item\label{ex33}
		\begin{prooftree}
			\AxiomC{g}
			\AxiomC{[g]$_1$}
			\AxiomC{(g $\multimap$ f)}
			\BinaryInfC{f}
			\RightLabel{\scriptsize{ABS$_1$}}
			\UnaryInfC{(g $\multimap$ f)}
			\BinaryInfC{f}
		\end{prooftree}

	\item\label{ex34}
		\begin{prooftree}
			\AxiomC{g}
			\AxiomC{[g]$_2$}
			\AxiomC{[g]$_1$}
			\AxiomC{(g $\multimap$ f)}
			\BinaryInfC{f}
			\RightLabel{\scriptsize{ABS$_1$}}
			\UnaryInfC{(g $\multimap$ f)}
			\BinaryInfC{f}
			\RightLabel{\scriptsize{ABS$_2$}}
			\UnaryInfC{(g $\multimap$ f)}
			\BinaryInfC{f}
		\end{prooftree}
\end{examples}

It should be clear that we could generate an infinite number of proofs following
this pattern of hypothesizing and retracting variables.  It should also be clear
that a single proof could involve an infinite number of these actions, and thus
cause ``proving'' to take forever.  This is a major problem because in glue
semantics we want to generate all possible proofs so that we can have all
possible readings since each new proof could potentially give a different
reading. 

The solution to this problem comes from \citep{GuptaLamping1998}.  The basic
idea is to ``compile'' linear logic formulas into ``skeletons", which are of the
form (g$_1$ $\multimap$ (g$_2$ $\multimap$ (\ldots $\multimap$ f))) where g$_i$
and f are propositions.  By doing this we are generating new premises for all of
the hypotheses that we would have needed to generate during the proof.  However,
by compiling, we ensure that we will never need to make any hypotheses, and can
therefore rid ourselves of the problematic rule (\ref{ex22}).

The algorithm for linear logic compilation from \citep{Lev2007} is given as \autoref{fig-compile}.

\begin{figure}[h]
	\hrule
	\begin{tabular}{l}
		\textbf{function} compile-glue-formula($\psi : X$) \cr
		~~~~$\langle Y,\Gamma\rangle :=$ compile-pos($X$) \cr
		~~~~\textbf{return} $\{\psi:Y:\{i\}\}\cup\Gamma$ for a fresh index $i$ \cr
		\cr
		\textbf{function} compile-pos(X) where $X$ atomic \cr
		~~~~\textbf{return} $\langle X_{[]},\emptyset\rangle$ \cr
		\cr
		\textbf{function} compile-pos($X \multimap Y$) \cr
		~~~~$\langle\delta,\Delta\rangle :=$ compile-pos($Y$) \cr
		~~~~$\langle\gamma,\Gamma\rangle :=$ compile-neg($X$) ($\gamma$ will be atomic)
		\cr
		~~~~\textbf{return} $\langle(\gamma\multimap\delta),\Gamma\cup\Delta\rangle$ \cr
		\cr
		\textbf{function} compile-neg(X) where $X$ atomic \cr
		~~~~\textbf{return} $\langle X_{[]},\emptyset\rangle$ \cr
		\cr
		\textbf{function} compile-neg($X \multimap Y$) \cr
		~~~~$\langle\delta_{L},\Delta\rangle :=$ compile-neg($Y$) ($\delta$ will be atomic) \cr
		~~~~$\langle\gamma,\Gamma\rangle :=$ compile-pos($X$) \cr
		~~~~\textbf{return} $\langle\delta_{[i|L]},\{v_{i}:\gamma:\{i\}\} \cup \Gamma \cup
		\Delta\rangle$ for a fresh index $i^\dagger$ \cr
	\end{tabular}
	\hrule
	$^\dagger$$[i|L]$ means a list whose head is $i$ and whose tail is $L$
	\caption{Linear Logic Compilation Algorithm} 
	\label{fig-compile}
\end{figure}

The compilation method changes our representation of a glue formula slightly
because it affixes a \textbf{list of indices} to every glue formula.  When a
premise is created, this list is instantiated with one unique index. 
Additionally, every atomic linear logic expression will have its own
\textbf{list of dependencies}. 

To turn our premises into ``skeletons", we must get rid of any non-atomic 
antecedents\footnote{We must also move through the formula recursively to ensure
that all of its subformulas are also skeletons.}. We will use (\ref{ex35}) as an
example.
\begin{examples}
	\item\label{ex35} `m : ((A $\multimap$ B) $\multimap$ C)' 
\end{examples}
To compile (\ref{ex35}) we would turn `A' into its own premise.  Since another
premise `A' might exist already, we must ensure that \textbf{this} `A' is the
one treated as the antecedent to `B'.  We do this by adding the newly created 
`A' premise's index to `B's list of dependencies.  Compilation of (\ref{ex35})
will return glue formulas (\ref{ex36}) and (\ref{ex37}).
\begin{examples}
	\item\label{ex37} `$v1$ : A : $\{1\}$' 
	\item\label{ex36} `$m$ : (B$_{[1]}$ $\multimap$ C) : $\{2\}$' 
\end{examples}

In the NLTK lite package, glue formula compilation can be performed using the
`compile()' method:

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater from nltk\_lite.semantics import glue \cr 
\textgreater\textgreater\textgreater g = glue.GlueFormula('m', '((A -o B) -o C)')  \cr
\textgreater\textgreater\textgreater gc = g.compile() \cr
\textgreater\textgreater\textgreater print gc[0] \cr
m : (-o B[1] C) : $\{2\}$ \cr
\textgreater\textgreater\textgreater print gc[1] \cr
v1 : A : $\{1\}$ \cr
\hline
\end{tabular}

\subsubsection{Horn Clause Application}
Naturally, we will have to incorporate the indices and dependencies into our
application rule from (\ref{ex8}).  The new rule is shown below as (\ref{ex38}):
\begin{examples}
	\item\label{ex38}
		\begin{prooftree}
			\AxiomC{$\phi$ : A : $\Gamma$}
			\AxiomC{$\psi$ : (A$_L$ $\multimap$ B) : $\Delta$}
			\RightLabel{provided $L \subset \Gamma$ and $L=[i_{1},\ldots,i_{n}]$}
			\BinaryInfC{($\psi$ $\lambda Vi_{1},\ldots,\lambda Vi_{n}.\phi$) : B : $\Gamma\cup\Delta$}
		\end{prooftree}
\end{examples}

You will notice that the set of indices of the conclusion is the sets of
indices of both premises combined.  This means that a glue formula's set
of indices is the set of premises that were consumed to generate that formula.
It should be noted that $\Gamma$ and $\Delta$ will always be disjoint since
the rules of linear logic say that no premise may be used more than once.  We
also impose the condition that `$\alpha$' must be a subset of `$\Gamma$'.  This
will ensure that the correct premises were used to generate the `A' premise used
in the application.

The requirement that $L$ be a subset of $\Gamma$ means that for the application
to be successful, $\phi$ must have already incorporated all of the dependencies
required by $L$.

The meaning term of the conclusion formula of (\ref{ex38}), `$\psi$' is not 
applied directly to `$\phi$'.  It is applied to a term that is generated by
adding $\lambda$-abstractions of each meaning term of an glue formula indexed by
an index in `$L$'.  It is important to maintain the order of the elements of
`$L$' since the order of the abstractions does matter.  When $n=0$, $\lambda
vi_{1},\ldots,\lambda vi_{n}.\phi$ is simply $\phi$.

The example below demonstrates how the NLTK handles horn clause applications:

\begin{tabular}{|l|}
\hline
\textgreater\textgreater\textgreater from nltk\_lite.semantics import glue \cr 
\textgreater\textgreater\textgreater a\_man =
glue.GlueFormula('\textbackslash\textbackslash Q.some x.((man x) and
(Q x))', '((g -o G) -o G)') \cr
\textgreater\textgreater\textgreater walks =
glue.GlueFormula('\textbackslash\textbackslash x.(walks x)', '(g -o f)') \cr
\textgreater\textgreater\textgreater amc =
a\_man.compile([1]) \cr
\textgreater\textgreater\textgreater g2 = amc[0] \cr
\textgreater\textgreater\textgreater g1 = amc[1] \cr
\textgreater\textgreater\textgreater g3 = walks.compile([3])[0] \cr
\textgreater\textgreater\textgreater g1 \cr
v1 : g : \{1\} \cr
\textgreater\textgreater\textgreater g2 \cr
\textbackslash Q.some x.(and (man x) (Q x)) : (-o G[1] G) : \{2\} \cr
\textgreater\textgreater\textgreater g3 \cr
\textbackslash x.(walks x) : (-o g f) : \{3\} \cr
\textgreater\textgreater\textgreater g13 = g3.applyto(g1) \cr
\textgreater\textgreater\textgreater g13 \cr
(\textbackslash x.(walks x) v1) : (-o g f g) : \{1, 3\} \cr
\textgreater\textgreater\textgreater g13.simplify() \cr
(walks v1) : f : \{1, 3\} \cr
\textgreater\textgreater\textgreater g123 = g2.applyto(g13) \cr
\textgreater\textgreater\textgreater g123.infixify() \cr
(\textbackslash Q.some x.((man x) and (Q x)) \textbackslash v1.(\textbackslash 
x.(walks x) v1)) : (G[1] -o G (g -o f g)) [(G, f)] : \{1, 2, 3\} \cr
\textgreater\textgreater\textgreater g123.simplify().infixify() \cr
some x.((man x) and (walks x)) : f : \{1, 2, 3\} \cr
\hline
\end{tabular}

\subsubsection{Machine Derivation}
The algorithm we will use to have the computer automatically assemble glue
proofs is from \citep{Lev2007}.  The algorithm starts with a list of compiled
glue formulas, called the $agenda$.  When it begins, it initializes two
dictionaries, one to hold atomic formulas, and the other to hold non-atomic
formulas (implications).  The algorithm then iterates as follows:

\begin{tabular}{l}
~~~~While the agenda is not empty, remove an element $cur$. \cr
~~~~~~~~If $cur$ is non-atomic: \cr
~~~~~~~~~~~~For each formula $atomic$ in the atomics dictionary that $cur$ can
be applied to: \cr
~~~~~~~~~~~~~~~~Apply $cur$ to $atomic$ and place the result in the $agenda$ \cr
~~~~~~~~~~~~Place $cur$ in the nonatomics dictionary \cr
~~~~~~~~Else $cur$ is atomic: \cr
~~~~~~~~~~~~For each formula $nonatomic$ in the nonatomics dictionary that can be applied
to $cur$: \cr
~~~~~~~~~~~~~~~~Apply $nonatomic$ to $cur$ and place the result in the $agenda$ \cr
~~~~~~~~~~~~Place $cur$ in the atomics dictionary \cr
~~~~Return the list of elements in the dictionaries with a complete set of
indices \cr
\end{tabular}

The algorithm is given as python code in \autoref{fig-deduction}.  The argument
passed to the function get\_readings is a list of compiled glue formulas.

\begin{figure}[h]
	\hrule
	\begin{tabular}{l}
def get\_readings(agenda): \cr
~~~~from nltk\_lite.semantics import glue \cr 
~~~~readings = [] \cr
~~~~agenda\_len = length(agenda) \cr
~~~~atomics = dict() \cr
~~~~nonatomics = dict() \cr
~~~~while agenda: \# is not empty \cr
~~~~~~~~cur = agenda.pop() \cr
~~~~~~~~\# if agenda.glue is non-atomic \cr
~~~~~~~~if isinstance(cur.glue.simplify(), linearlogic.ApplicationExpression): \cr
~~~~~~~~~~~~for key in atomics: \cr
~~~~~~~~~~~~~~~~if cur.glue.simplify().first.second.can\_unify\_with(key, cur.glue.varbindings): \cr
~~~~~~~~~~~~~~~~~~~~for atomic in atomics[key]: \cr
~~~~~~~~~~~~~~~~~~~~~~~~if cur.indices.intersection(atomic.indices): \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~continue \cr
~~~~~~~~~~~~~~~~~~~~~~~~else: \# if the sets of indices are disjoint \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~try: \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~agenda.append(cur.applyto(atomic)) \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~except linearlogic.LinearLogicApplicationError: \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~pass \cr
~~~~~~~~~~~~try: \cr
~~~~~~~~~~~~~~~~nonatomics[cur.glue.simplify().first.second].append(cur) \cr
~~~~~~~~~~~~except KeyError: \cr
~~~~~~~~~~~~~~~~nonatomics[cur.glue.simplify().first.second] = [cur] \cr
 \cr
~~~~~~~~else: \# else agenda.glue is atomic \cr
~~~~~~~~~~~~for key in nonatomics: \cr
~~~~~~~~~~~~~~~~for nonatomic in nonatomics[key]: \cr
~~~~~~~~~~~~~~~~~~~~if cur.glue.simplify().can\_unify\_with(key, nonatomic.glue.varbindings): \cr
~~~~~~~~~~~~~~~~~~~~~~~~if cur.indices.intersection(nonatomic.indices): \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~continue \cr
~~~~~~~~~~~~~~~~~~~~~~~~else: \# if the sets of indices are disjoint \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~try: \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~agenda.append(nonatomic.applyto(cur)) \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~except linearlogic.LinearLogicApplicationError: \cr
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~pass \cr
~~~~~~~~~~~~try: \cr
~~~~~~~~~~~~~~~~atomics[cur.glue.simplify()].append(cur) \cr
~~~~~~~~~~~~except KeyError: \cr
~~~~~~~~~~~~~~~~atomics[cur.glue.simplify()] = [cur] \cr
 \cr
~~~~for entry in atomics: \cr
~~~~~~~~for gf in atomics[entry]: \cr
~~~~~~~~~~~~if len(gf.indices) == agenda\_length: \cr
~~~~~~~~~~~~~~~~readings.append(gf.meaning) \cr
~~~~for entry in nonatomics: \cr
~~~~~~~~for gf in nonatomics[entry]: \cr
~~~~~~~~~~~~if len(gf.indices) == agenda\_length: \cr
~~~~~~~~~~~~~~~~readings.append(gf.meaning) \cr
~~~~return readings \cr
	\end{tabular}
	\hrule
	\caption{Machine Deduction Code}
	\label{fig-deduction}
\end{figure}

\subsection{Further Reading}
See http://www-csli.stanford.edu/\~iddolev/glue\_bibliography.html for a
comprehensive bibliography of glue semantics literature put together by Iddo
Lev.

\bibliography{glue}

\end{document}
