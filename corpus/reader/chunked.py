# Natural Language Toolkit: Chunked Corpus Reader
#
# Copyright (C) 2001-2007 University of Pennsylvania
# Author: Steven Bird <sb@ldc.upenn.edu>
#         Edward Loper <edloper@gradient.cis.upenn.edu>
# URL: <http://nltk.sf.net>
# For license information, see LICENSE.TXT

"""
A reader for corpora that contain chunked (and optionally tagged)
documents.
"""

from nltk.corpus.reader.util import *
from nltk.corpus.reader.api import *
from nltk.corpus.reader.bracket_parse import BracketParseCorpusReader
from nltk.tree import Tree
from nltk.tokenize import *
from nltk import chunk
import os.path

class ChunkedCorpusReader(CorpusReader):
    """
    Reader for chunked (and optionally tagged) corpora.  Paragraphs
    are split using a block reader.  They are then tokenized into
    sentences using a sentence tokenizer.  Finally, these sentences
    are parsed into chunk trees using a string-to-chunktree conversion
    function.  Each of these steps can be performed using a default
    function or a custom function.  By default, paragraphs are split
    on blank lines; sentences are listed one per line; and sentences
    are parsed into chunk trees using L{chunk.tagstr2tree}.
    """
    def __init__(self, root, items, extension='', 
                 str2chunktree=chunk.tagstr2tree,
                 sent_tokenizer=RegexpTokenizer('\n', gaps=True),
                 para_block_reader=read_blankline_block):
        """
        @param root: The root directory for this corpus.
        @param items: A list of items in this corpus.
        @param extension: File extension for items in this corpus.
        """
        self._root = root
        """The root directory for this corpus."""
        
        if isinstance(items, basestring):
            items = find_corpus_items(root, items, extension)
        self._items = items
        """A list of items in this corpus."""
        
        self._extension = extension
        """File extension for items in this corpus."""

        self._cv_args = (str2chunktree, sent_tokenizer, para_block_reader)
        """Arguments for corpus views generated by this corpus."""

    root = property(lambda self: self._root, doc="""
        The directory where this corpus is stored..""")

    items = property(lambda self: self._items, doc="""
        A list of the documents in this corpus""")
    
    def raw(self, items=None):
        """
        @return: the given document or documents as a single string.
        @rtype: C{str}
        """
        return concat([open(filename).read()
                       for filename in self._item_filenames(items)])

    def words(self, items=None):
        """
        @return: the given document or documents as a list of words
            and punctuation symbols.
        @rtype: C{list} of C{str}
        """
        return concat([ChunkedCorpusView(f, 0, 0, 0, 0, *self._cv_args)
                       for f in self._item_filenames(items)])

    def sents(self, items=None):
        """
        @return: the given document or documents as a list of
            sentences or utterances, each encoded as a list of word
            strings.
        @rtype: C{list} of (C{list} of C{str})
        """
        return concat([ChunkedCorpusView(f, 0, 1, 0, 0, *self._cv_args)
                       for f in self._item_filenames(items)])

    def paras(self, items=None):
        """
        @return: the given document or documents as a list of
            paragraphs, each encoded as a list of sentences, which are
            in turn encoded as lists of word strings.
        @rtype: C{list} of (C{list} of (C{list} of C{str}))
        """
        return concat([ChunkedCorpusView(f, 0, 1, 1, 0, *self._cv_args)
                       for f in self._item_filenames(items)])

    def tagged_words(self, items=None):
        """
        @return: the given document or documents as a list of tagged
            words and punctuation symbols, encoded as tuples
            C{(word,tag)}.
        @rtype: C{list} of C{(str,str)}
        """
        return concat([ChunkedCorpusView(f, 1, 0, 0, 0, *self._cv_args)
                       for f in self._item_filenames(items)])

    def tagged_sents(self, items=None):
        """
        @return: the given document or documents as a list of
            sentences, each encoded as a list of C{(word,tag)} tuples.
            
        @rtype: C{list} of (C{list} of C{(str,str)})
        """
        return concat([ChunkedCorpusView(f, 1, 1, 0, 0, *self._cv_args)
                       for f in self._item_filenames(items)])

    def tagged_paras(self, items=None):
        """
        @return: the given document or documents as a list of
            paragraphs, each encoded as a list of sentences, which are
            in turn encoded as lists of C{(word,tag)} tuples.
        @rtype: C{list} of (C{list} of (C{list} of C{(str,str)}))
        """
        return concat([ChunkedCorpusView(f, 1, 1, 1, 0, *self._cv_args)
                       for f in self._item_filenames(items)])

    def chunked_words(self, items=None):
        """
        @return: the given document or documents as a list of tagged
            words and chunks.  Words are encoded as C{(word, tag)}
            tuples (if the corpus has tags) or word strings (if the
            corpus has no tags).  Chunks are encoded as depth-one
            trees over C{(word,tag)} tuples or word strings.
        @rtype: C{list} of (C{(str,str)} and L{Tree})
        """
        return concat([ChunkedCorpusView(f, 1, 0, 0, 1, *self._cv_args)
                       for f in self._item_filenames(items)])

    def chunked_sents(self, items=None):
        """
        @return: the given document or document as a list of
            sentences, each encoded as a shallow C{Tree}.  The leaves
            of these trees are encoded as C{(word, tag)} tuples (if
            the corpus has tags) or word strings (if the corpus has no
            tags).
        @rtype: C{list} of L{Tree}
        """
        return concat([ChunkedCorpusView(f, 1, 1, 0, 1, *self._cv_args)
                       for f in self._item_filenames(items)])

    def chunked_paras(self, items=None):
        """
        @return: the given document or documents as a list of
            paragraphs, each encoded as a list of sentences, which are
            in turn encoded as a shallow C{Tree}.  The leaves of these
            trees are encoded as C{(word, tag)} tuples (if the corpus
            has tags) or word strings (if the corpus has no tags).
        @rtype: C{list} of (C{list} of L{Tree})
        """
        return concat([ChunkedCorpusView(f, 1, 1, 1, 1, *self._cv_args)
                       for f in self._item_filenames(items)])

    def _item_filenames(self, items):
        if items is None: items = self.items
        if isinstance(items, basestring): items = [items]
        return [os.path.join(self._root, '%s%s' % (item, self._extension))
                for item in items]
        
    def _read_block(self, stream):
        return [chunk.tagstr2tree(t) for t in
                read_blankline_block(stream)]

class ChunkedCorpusView(StreamBackedCorpusView):
    def __init__(self, filename, tagged, group_by_sent, group_by_para,
                 chunked, str2chunktree, sent_tokenizer, para_block_reader):
        StreamBackedCorpusView.__init__(self, filename)
        self._tagged = tagged
        self._group_by_sent = group_by_sent
        self._group_by_para = group_by_para
        self._chunked = chunked
        self._str2chunktree = str2chunktree
        self._sent_tokenizer = sent_tokenizer
        self._para_block_reader = para_block_reader

    def read_block(self, stream):
        block = []
        for para_str in self._para_block_reader(stream):
            para = []
            for sent_str in self._sent_tokenizer.tokenize(para_str):
                sent = self._str2chunktree(sent_str)
                
                # If requested, throw away the tags.
                if not self._tagged:
                    sent = self._untag(sent)

                # If requested, throw away the chunks.
                if not self._chunked:
                    sent = sent.leaves()

                # Add the sentence to `para`.
                if self._group_by_sent:
                    para.append(sent)
                else:
                    para.extend(sent)
                    
            # Add the paragraph to `block`.
            if self._group_by_para:
                block.append(para)
            else:
                block.extend(para)
                
        # Return the block
        return block

    def _untag(self, tree):
        for i, child in enumerate(tree):
            if isinstance(child, Tree):
                self._untag(child)
            elif isinstance(child, tuple):
                tree[i] = child[0]
            else:
                raise ValueError('expected child to be Tree or tuple')
        return tree
    
