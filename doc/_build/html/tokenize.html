

<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>nltk.tokenize &mdash; NLTK vr2 documentation</title>
    <link rel="stylesheet" href="_static/default.css" type="text/css" />
    <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '',
        VERSION:     'r2',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="_static/jquery.js"></script>
    <script type="text/javascript" src="_static/underscore.js"></script>
    <script type="text/javascript" src="_static/doctools.js"></script>
    <link rel="top" title="NLTK vr2 documentation" href="index.html" />
    <link rel="up" title="API Documentation" href="api.html" />
    <link rel="next" title="nltk.toolbox" href="toolbox.html" />
    <link rel="prev" title="nltk.tag" href="tag.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="toolbox.html" title="nltk.toolbox"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="tag.html" title="nltk.tag"
             accesskey="P">previous</a> |</li>
        <li><a href="index.html">NLTK vr2 documentation</a> &raquo;</li>
          <li><a href="api.html" accesskey="U">API Documentation</a> &raquo;</li> 
      </ul>
    </div>  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="module-nltk.tokenize">
<span id="nltk-tokenize"></span><h1>nltk.tokenize<a class="headerlink" href="#module-nltk.tokenize" title="Permalink to this headline">¶</a></h1>
<p>Functions for X{tokenizing}, i.e., dividing text strings into
substrings.</p>
<dl class="class">
<dt id="nltk.tokenize.WhitespaceTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">WhitespaceTokenizer</tt><a class="headerlink" href="#nltk.tokenize.WhitespaceTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A tokenizer that divides a string into substrings by treating any
sequence of whitespace characters as a separator.  Whitespace
characters are space (C{&#8216; &#8216;}), tab (C{&#8216;t&#8217;}), and newline
(C{&#8216;n&#8217;}).  If you are performing the tokenization yourself
(rather than building a tokenizer to pass to some other piece of
code), consider using the string C{split()} method instead:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">words</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">()</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.SpaceTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">SpaceTokenizer</tt><a class="headerlink" href="#nltk.tokenize.SpaceTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A tokenizer that divides a string into substrings by treating any
single space character as a separator.  If you are performing the
tokenization yourself (rather than building a tokenizer to pass to
some other piece of code), consider using the string C{split()}
method instead:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">words</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39; &#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.TabTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">TabTokenizer</tt><a class="headerlink" href="#nltk.tokenize.TabTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A tokenizer that divides a string into substrings by treating any
single tab character as a separator.  If you are performing the
tokenization yourself (rather than building a tokenizer to pass to
some other piece of code), consider using the string C{split()}
method instead:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">words</span> <span class="o">=</span> <span class="n">s</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s">&#39;</span><span class="se">\t</span><span class="s">&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.LineTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">LineTokenizer</tt><big>(</big><em>blanklines='discard'</em><big>)</big><a class="headerlink" href="#nltk.tokenize.LineTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A tokenizer that divides a string into substrings by treating any
single newline character as a separator.  Handling of blank lines
may be controlled using a constructor parameter.</p>
</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.RegexpTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">RegexpTokenizer</tt><big>(</big><em>pattern</em>, <em>gaps=False</em>, <em>discard_empty=True</em>, <em>flags=56</em><big>)</big><a class="headerlink" href="#nltk.tokenize.RegexpTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A tokenizer that splits a string into substrings using a regular
expression.  The regular expression can be specified to match
either tokens or separators between tokens.</p>
<p>Unlike C{re.findall()} and C{re.split()}, C{RegexpTokenizer} does
not treat regular expressions that contain grouping parenthases
specially.</p>
</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.BlanklineTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">BlanklineTokenizer</tt><a class="headerlink" href="#nltk.tokenize.BlanklineTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A tokenizer that divides a string into substrings by treating any
sequence of blank lines as a separator.  Blank lines are defined
as lines containing no characters, or containing only space
(C{&#8216; &#8216;}) or tab (C{&#8216;        &#8216;}) characters.</p>
</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.WordPunctTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">WordPunctTokenizer</tt><a class="headerlink" href="#nltk.tokenize.WordPunctTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A tokenizer that divides a text into sequences of alphabetic and
non-alphabetic characters.  E.g.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">WordPunctTokenizer</span><span class="p">()</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s">&quot;She said &#39;hello&#39;.&quot;</span><span class="p">)</span>
<span class="go">[&#39;She&#39;, &#39;said&#39;, &quot;&#39;&quot;, &#39;hello&#39;, &quot;&#39;.&quot;]</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="nltk.tokenize.regexp_tokenize">
<tt class="descclassname">nltk.tokenize.</tt><tt class="descname">regexp_tokenize</tt><big>(</big><em>text</em>, <em>pattern</em>, <em>gaps=False</em>, <em>discard_empty=True</em>, <em>flags=56</em><big>)</big><a class="headerlink" href="#nltk.tokenize.regexp_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Split the given text string, based on the given regular expression
pattern.  See the documentation for L{RegexpTokenizer.tokenize()}
for descriptions of the arguments.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.tokenize.word_tokenize">
<tt class="descclassname">nltk.tokenize.</tt><tt class="descname">word_tokenize</tt><big>(</big><em>text</em><big>)</big><a class="reference internal" href="_modules/nltk/tokenize.html#word_tokenize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tokenize.word_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Use NLTK&#8217;s currently recommended word tokenizer to tokenize words
in the given sentence.  Currently, this uses
L{TreebankWordTokenizer}.  This tokenizer should be fed a single
sentence at a time.</p>
</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.SExprTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">SExprTokenizer</tt><big>(</big><em>parens='()'</em>, <em>strict=True</em><big>)</big><a class="headerlink" href="#nltk.tokenize.SExprTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A tokenizer that divides strings into X{s-expressions}.  An
s-expresion can be either:</p>
<blockquote>
<div><ul class="simple">
<li>A parenthasized expression, including any nested parenthasized
expressions.</li>
<li>A sequence of non-whitespace non-parenthasis characters.</li>
</ul>
</div></blockquote>
<p>For example, the string C{&#8216;(a (b c)) d e (f)&#8217;} consists of four
s-expressions: C{&#8216;(a (b c))&#8217;}, C{&#8216;d&#8217;}, C{&#8216;e&#8217;}, and C{&#8216;(f)&#8217;}.</p>
<dl class="method">
<dt id="nltk.tokenize.SExprTokenizer.tokenize">
<tt class="descname">tokenize</tt><big>(</big><em>text</em><big>)</big><a class="headerlink" href="#nltk.tokenize.SExprTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Tokenize the text into s-expressions.  For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">SExprTokenizer</span><span class="p">()</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s">&#39;(a b (c d)) e f (g)&#39;</span><span class="p">)</span>
<span class="go">[&#39;(a b (c d))&#39;, &#39;e&#39;, &#39;f&#39;, &#39;(g)&#39;]</span>
</pre></div>
</div>
<p>All parenthases are assumed to mark sexprs.  In particular, no
special processing is done to exclude parenthases that occur
inside strings, or following backslash characters.</p>
<p>If the given expression contains non-matching parenthases,
then the behavior of the tokenizer depends on the C{strict}
parameter to the constructor.  If C{strict} is C{True}, then
raise a C{ValueError}.  If C{strict} is C{False}, then any
unmatched close parenthases will be listed as their own
s-expression; and the last partial sexpr with unmatched open
parenthases will be listed as its own sexpr:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">SExprTokenizer</span><span class="p">(</span><span class="n">strict</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span><span class="o">.</span><span class="n">tokenize</span><span class="p">(</span><span class="s">&#39;c) d) e (f (g&#39;</span><span class="p">)</span>
<span class="go">[&#39;c&#39;, &#39;)&#39;, &#39;d&#39;, &#39;)&#39;, &#39;e&#39;, &#39;(f (g&#39;]</span>
</pre></div>
</div>
<p>&#64;param text: the string to be tokenized
&#64;type text: C{string} or C{iter(string)}
&#64;return: An iterator over tokens (each of which is an s-expression)</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.PunktSentenceTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">PunktSentenceTokenizer</tt><big>(</big><em>train_text=None</em>, <em>verbose=False</em>, <em>lang_vars=&lt;nltk.tokenize.punkt.PunktLanguageVars object at 0x33f3710&gt;</em>, <em>token_cls=&lt;class 'nltk.tokenize.punkt.PunktToken'&gt;</em><big>)</big><a class="headerlink" href="#nltk.tokenize.PunktSentenceTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A sentence tokenizer which uses an unsupervised algorithm to build
a model for abbreviation words, collocations, and words that start
sentences; and then uses that model to find sentence boundaries.
This approach has been shown to work well for many European
languages.</p>
<dl class="method">
<dt id="nltk.tokenize.PunktSentenceTokenizer.sentences_from_text">
<tt class="descname">sentences_from_text</tt><big>(</big><em>text</em>, <em>realign_boundaries=False</em><big>)</big><a class="headerlink" href="#nltk.tokenize.PunktSentenceTokenizer.sentences_from_text" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a text, generates the sentences in that text by only
testing candidate sentence breaks. If realign_boundaries is
True, includes in the sentence closing punctuation that
follows the period.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tokenize.PunktSentenceTokenizer.sentences_from_text_legacy">
<tt class="descname">sentences_from_text_legacy</tt><big>(</big><em>text</em><big>)</big><a class="headerlink" href="#nltk.tokenize.PunktSentenceTokenizer.sentences_from_text_legacy" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a text, generates the sentences in that text. Annotates all
tokens, rather than just those with possible sentence breaks. Should
produce the same results as L{sentences_from_text}.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tokenize.PunktSentenceTokenizer.sentences_from_tokens">
<tt class="descname">sentences_from_tokens</tt><big>(</big><em>tokens</em><big>)</big><a class="headerlink" href="#nltk.tokenize.PunktSentenceTokenizer.sentences_from_tokens" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a sequence of tokens, generates lists of tokens, each list
corresponding to a sentence.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tokenize.PunktSentenceTokenizer.span_tokenize">
<tt class="descname">span_tokenize</tt><big>(</big><em>text</em><big>)</big><a class="headerlink" href="#nltk.tokenize.PunktSentenceTokenizer.span_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a text, returns a list of the (start, end) spans of sentences
in the text.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tokenize.PunktSentenceTokenizer.text_contains_sentbreak">
<tt class="descname">text_contains_sentbreak</tt><big>(</big><em>text</em><big>)</big><a class="headerlink" href="#nltk.tokenize.PunktSentenceTokenizer.text_contains_sentbreak" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns True if the given text includes a sentence break.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tokenize.PunktSentenceTokenizer.tokenize">
<tt class="descname">tokenize</tt><big>(</big><em>text</em>, <em>realign_boundaries=False</em><big>)</big><a class="headerlink" href="#nltk.tokenize.PunktSentenceTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Given a text, returns a list of the sentences in that text.</p>
</dd></dl>

<dl class="method">
<dt id="nltk.tokenize.PunktSentenceTokenizer.train">
<tt class="descname">train</tt><big>(</big><em>train_text</em>, <em>verbose=False</em><big>)</big><a class="headerlink" href="#nltk.tokenize.PunktSentenceTokenizer.train" title="Permalink to this definition">¶</a></dt>
<dd><p>Derives parameters from a given training text, or uses the parameters
given. Repeated calls to this method destroy previous parameters. For
incremental training, instantiate a separate PunktTrainer instance.</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.TreebankWordTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">TreebankWordTokenizer</tt><a class="headerlink" href="#nltk.tokenize.TreebankWordTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A word tokenizer that tokenizes sentences using the conventions
used by the Penn Treebank.  Contractions, such as &#8220;can&#8217;t&#8221;, are
split in to two tokens.  E.g.:</p>
<blockquote>
<div><ul class="simple">
<li>can&#8217;t S{-&gt;} ca n&#8217;t</li>
<li>he&#8217;ll S{-&gt;} he &#8216;ll</li>
<li>weren&#8217;t S{-} were n&#8217;t</li>
</ul>
</div></blockquote>
<p>This tokenizer assumes that the text has already been segmented into
sentences.  Any periods &#8211; apart from those at the end of a string &#8211;
are assumed to be part of the word they are attached to (e.g. for
abbreviations, etc), and are not separately tokenized.</p>
</dd></dl>

<dl class="function">
<dt id="nltk.tokenize.sent_tokenize">
<tt class="descclassname">nltk.tokenize.</tt><tt class="descname">sent_tokenize</tt><big>(</big><em>text</em><big>)</big><a class="reference internal" href="_modules/nltk/tokenize.html#sent_tokenize"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nltk.tokenize.sent_tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>Use NLTK&#8217;s currently recommended sentence tokenizer to tokenize
sentences in the given text.  Currently, this uses
L{PunktSentenceTokenizer}.</p>
</dd></dl>

<dl class="function">
<dt>
<tt class="descclassname">nltk.tokenize.</tt><tt class="descname">word_tokenize</tt><big>(</big><em>text</em><big>)</big><a class="reference internal" href="_modules/nltk/tokenize.html#word_tokenize"><span class="viewcode-link">[source]</span></a></dt>
<dd><p>Use NLTK&#8217;s currently recommended word tokenizer to tokenize words
in the given sentence.  Currently, this uses
L{TreebankWordTokenizer}.  This tokenizer should be fed a single
sentence at a time.</p>
</dd></dl>

<dl class="class">
<dt id="nltk.tokenize.TextTilingTokenizer">
<em class="property">class </em><tt class="descclassname">nltk.tokenize.</tt><tt class="descname">TextTilingTokenizer</tt><big>(</big><em>w=20, k=10, similarity_method=0, stopwords=None, smoothing_method=[0], smoothing_width=2, smoothing_rounds=1, cutoff_policy=1, demo_mode=False</em><big>)</big><a class="headerlink" href="#nltk.tokenize.TextTilingTokenizer" title="Permalink to this definition">¶</a></dt>
<dd><p>A section tokenizer based on the TextTiling algorithm. The
algorithm detects subtopic shifts based on the analysis of lexical
co-occurence patterns.</p>
<p>The process starts by tokenizing the text into pseudosentences of
a fixed size w. Then, depending on the method used, similarity
scores are assigned at sentence gaps. The algorithm proceeds by
detecting the peak differences between these scores and marking
them as boundaries. The boundaries are normalized to the closest
paragraph break and the segmented text is returned.</p>
<p>&#64;type w: number
&#64;param w: Pseudosentence size
&#64;type k: number
&#64;param k: Size(in sentences) of the block used in the block comparison</p>
<blockquote>
<div>method</div></blockquote>
<p>&#64;type similarity_method: constant
&#64;param similarity_method: The method used for determining similarity scores
&#64;type stopwords: list
&#64;param stopwords: A list of stopwords that are filtered out
&#64;type smoothing_method: constant
&#64;param smoothing_method: The method used for smoothing the score plot
&#64;type smoothing_width: number
&#64;param smoothing_width: The width of the window used by the smoothing</p>
<blockquote>
<div>method</div></blockquote>
<p>&#64;type smoothing_rounds: number
&#64;param smoothing_rounds: The number of smoothing passes
&#64;type cutoff_policy: constant
&#64;param cutoff_policy: The policy used to determine the number of boundaries</p>
<dl class="method">
<dt id="nltk.tokenize.TextTilingTokenizer.tokenize">
<tt class="descname">tokenize</tt><big>(</big><em>text</em><big>)</big><a class="headerlink" href="#nltk.tokenize.TextTilingTokenizer.tokenize" title="Permalink to this definition">¶</a></dt>
<dd><p>The main function. Follows a pipeline structure.</p>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="tag.html"
                        title="previous chapter">nltk.tag</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="toolbox.html"
                        title="next chapter">nltk.toolbox</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="_sources/tokenize.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="toolbox.html" title="nltk.toolbox"
             >next</a> |</li>
        <li class="right" >
          <a href="tag.html" title="nltk.tag"
             >previous</a> |</li>
        <li><a href="index.html">NLTK vr2 documentation</a> &raquo;</li>
          <li><a href="api.html" >API Documentation</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011, Steven Bird, Ewan Klein, Edward Loper.
      Created using <a href="http://sphinx.pocoo.org/">Sphinx</a> 1.0.8.
    </div>
  </body>
</html>