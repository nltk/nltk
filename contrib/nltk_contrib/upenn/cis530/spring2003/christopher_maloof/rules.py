import nltk.tagger
import nltk.token

class TemplateI:
    """
    An interface for producing transformations that apply at given corpus positions.
    """
    def __init__(self):
        assert False, "TemplateI is an abstract interface"

    def makeApplicableRules(self, tokens, index, correctTag):
        """
        Constructs a list of zero or more transformations that would change
        the tag of C{tokens[index]} to C{correctTag}, given
        the context in C{tokens}.

        (If the tags are already identical, returns
        the empty list.)

        @param tokens: A corpus of tagged C{Token}s
        @type tokens: list of Token
        @param index: The index of C{tokens} to be corrected by returned rules
        @type index: int
        @param correctTag: The correct tag for C{tokens[index]}
        @type correctTag: any
        @return: A list of transformations that would correct the tag of
        C{tokens[index]}, or the empty list if the tag is correct already.
        @rtype: list of RuleI
        """
        assert False, "TemplateI is an abstract interface"

    
    def getNeighborhood (self, tokens, index):
        """
        Returns the set of indices C{i} such that changing the tag of
        C{tokens[i]} might cause the C{makeApplicableRules} method of this
        template to generate a different list of rules when called on
        C{tokens} and C{index}.

        The returned set always includes C{index}, because changing the tag of
        C{tokens[index]} makes a completely different set of rules apply.

        This method is only important for the "fast" Brill tagger.

        @param tokens: A corpus of tagged C{Token}s
        @type tokens: list of Token
        @param index: The index in C{tokens} to consider
        @type index: int
        @return: The set of indices which might influence which rules apply
        to C{tokens[index]}
        @rtype: dict of int -> None
        """
        assert False, "TemplateI is an abstract interface"
        #return range( max(index-3,0), min(index+4,len(tokens)) )


class ProximateTokensTemplateI(TemplateI):
    """
    For generating rules of the form 'If the M{n}th token is tagged C{A}, and any
    token between M{n+start} and M{n+end} has property C{B}, and ... , then change
    the tag of the M{n}th token from C{A} to C{C}.'  For example, M{start=end=-1}
    would refer to rules that check just the preceding token's tag.  Note that
    multiple tests may be included in a rule; the rule applies if they all hold.

    The return value of C{extractProperty} must represent a token property.
    The rules generated by this template check extracted properties for equality.
    For example, C{extractProperty} could be defined to pull out a token's tag or
    its base lexical item: see L{C{ProximateTagsTemplate}} and
    L{C{ProximateWordsTemplate}}.
    """
    
    # List of 2-tuples of ints.
    def __init__(self, boundaryList, proximateRuleType):
        """
        Constructs a template for generating rules.  C{boundaryList} is a list
        of 2-tuples of C{int}s, or a single such 2-tuple.  Each pair represents
        a part of the corpus which a condition of generated rules refers to,
        relative to the token affected.
        
        Using C{boundaryList=(-2,-1)} results in a template for rules which
        apply to token C{T} if either of the two tokens preceding C{T} has a particular
        property.  Using C{boundaryList=[(-2,-1), (1,1)]} produces rules which
        impose an additional requirement on the token following C{T}.

        The transformations produced are constructed by calling C{proximateRuleType)
        on appropriate arguments.  B{The return value of C{extractProperty} must
        equal the return value of the C{extractProperty} method of the object
        constructed by C{proximateRuleType}!}

        This constructor is abstract and should only be called by subclasses.

        @param boundaryList: Tuples representing how far from a token a rule
        may apply.
        @type boundaryList: 2-tuple of int, or list of 2-tuple of int
        @param proximateRuleType: A constructor for a subclass of ProximateRuleI.
        @type proximateRuleType: function
        """
        if len(boundaryList) == 2 and type(boundaryList[0]) == int \
                                  and type(boundaryList[1]) == int:
            self._boundaryList = [boundaryList]
        else:
            self._boundaryList = boundaryList[:]
        self._proximateRuleType = proximateRuleType

    # Returns a list of Rules that would make the right correction at
    # the indicated site.
    # All lists should be unique if the tuples in _boundaryList are unique.
    def makeApplicableRules (self, tokens, index, correctTag):
        """
        See L{TemplateI} for full specifications.

        @rtype: list of ProximateTokensRuleI
        """
        if tokens[index]['TAG'] == correctTag:
            return []
        
        subruleSets = []
        for (start, end) in self._boundaryList:
            # Each Rule may have multiple subrule conditions for its application, each
            # one matching an element of boundaryList.
            # Collect the set of conditions that would satisfy this particular
            # (start,end) subrule.  (Not a list; we don't want repeats.)
            subrules = {}
            # A match anywhere in this range will suffice for this condition.
            for j in range(max(0, index+start), min(index+end+1, len(tokens))):
                subrules[ (start, end,
                           self.extractProperty(tokens[j])) ] = None

            subruleSets.append(subrules)

        # Now, cross the sets of subrules, as any combination would match this index
        # in the token list.  Obtain a list of lists of tuples.  Each list will
        # correspond to a Rule we generate, each tuple to a condition in that Rule.
        if len(subruleSets) != 1:
            tupleLists = reduce(_crossLists, map(dict.keys, subruleSets), [[]])
        else:
            # for speed in the common case
            tupleLists = [[r] for r in subruleSets[0].keys()]
            
        # Finally, translate the tuples into rules and return them.
        return [ self._proximateRuleType(x, tokens[index]['TAG'], correctTag)
                 for x in tupleLists ]
    
    # extractProperty is a function on tagged tokens that returns a value.
    # WARNING: The template and its rule type had better have the same implementation.
    # (Can't just pass the function to the rules, because that makes rules unpicklable.
    #  And Python lacks static methods, so can't call a rule function from here.)
    def extractProperty (self, token):
        """
        Returns some property characterizing this token, such as its base lexical
        item or its tag.

        Each implentation of this method should correspond to an implementation of
        the method with the same name in a subclass of L{C{ProximateTokensRuleI}}.

        @param token: The token
        @type token: Token
        @return: The property
        @rtype: any
        """
        assert False, "ProximateTokensTemplateI is an abstract interface"

    def getNeighborhood (self, tokens, index):
        # inherit docs from TemplateI
        neighborhood = {index: None}
        for (start, end) in self._boundaryList:
            for i in range( max(0, index+start), min(index+end+1, len(tokens)) ):
                neighborhood[i] = None

        return neighborhood


# Returns a much longer list of slightly longer lists.
# In particular, each element in listOfSingles is appended to each list in
# listOfLists, and the resulting big list is returned.
def _crossLists(listOfLists, listOfSingles):
    return [ j + [k] for j in listOfLists for k in listOfSingles ]    

class RuleI:
    """
    An interface for a transformation that can be applied to a tagged corpus.

    The transformation is of the form: For each token in the corpus tagged C{X},
    if I{condition}, then change the tag of the token to C{Y}.  C{X} and C{Y}
    are fixed for each C{RuleI}.  I{condition} may refer to the token and the
    remainder of the corpus.
    """
    def __init__(self):
        assert False, "RuleI is an abstract interface"
    
    def applyTo(self, tokens):
        """
        Applies the rule to the corpus.

        @param tokens: The tagged corpus
        @type tokens: list of Token
        @return: The indices of tokens whose tags were changed by this rule
        @rtype: list of int
        """
        return self.applyAt(tokens, range(len(tokens)))

    # Applies this rule at the given positions in the corpus
    # Returns the positions affected by the application
    def applyAt(self, tokens, positions):
        """
        Applies the rule to the indicated indices of the corpus.  (The rule's
        conditions are still tested.)

        @param tokens: The tagged corpus
        @type tokens: list of Token
        @param positions: The positions where the transformation is to be tried
        @return: The indices of tokens whose tags were changed by this rule
        @rtype: list of int
        """
        assert False, "RuleI is an abstract interface"

    # Returns 1 if the rule would apply at the given index in tokens
    def applies(self, tokens, index):
        """
        Indicates whether this rule would make a change at C{tokens[index]}.

        @param tokens: A tagged corpus
        @type tokens: list of Token
        @param index: The index to check
        @type index: int
        @return: True if the rule would change the tag of C{tokens[index]},
            False otherwise
        @rtype: Boolean
        """
        assert False, "RuleI is an abstract interface"
        
    def getOriginal(self):
        """
        Returns the tag C{X} which this C{RuleI} may cause to be replaced.

        @return: The tag targeted by this rule
        @rtype: any
        """
        assert False, "RuleI is an abstract interface"

    def getReplacement(self):
        """
        Returns the tag C{Y} with which this C{RuleI} may replace another tag.

        @return: The tag created by this rule
        @rtype: any
        """
        assert False, "RuleI is an abstract interface"

    # Rules must be comparable and hashable for the algorithm to work
    def __eq__(self):
        assert False, "RuleI is an abstract interface"

    def __hash__(self):
        assert False, "RuleI is an abstract interface"

class ProximateTokensRuleI (RuleI):
    """
    A rule of the form 'If the M{n}th token is tagged C{A}, and any token
    between M{n+start} and M{n+end} has property C{B}, and ... , then change the
    tag of the M{n}th token from C{A} to C{C}.'  For example, M{start=end=-1} would
    refer to rules that check just the property of the preceding token.  Note that
    multiple tests may be included in a rule; the rule applies if they all hold.

    A C{ProximateTokensRuleI} is determined by the values of C{A} and C{C} plus
    a list of C{(start, end, property)} triples.

    The return value of C{extractProperty} must represent a token property.
    For example, C{extractProperty} could be defined to return a
    token's tag or its base lexical item: see L{C{ProximateTagsTemplate}} and
    L{C{ProximateWordsTemplate}}.
    """
    def __init__(self, conditionList, original, replacement):
        """
        Constructs a new rule that changes the tag C{original} to the tag
        C{replacement} if all the properties in C{conditionList} hold.

        C{conditionList} is a single 3-tuple C{(start, end, property)} or a list
        of such 3-tuples.  Each tuple represents an interval relative to a token
        plus a property which must hold for at least one token in the interval
        in order for the rule to apply.  A C{ProximateTokensRuleI} constructed
        with C{conditionList=(-2,-1, "NN")} applies to a token C{T} only if
        C{extractProperty} returns "NN" when applied to one of the two tokens
        preceding C{T}.

        This constructor is abstract and should only be called by subclasses.
        """

        if len(conditionList) == 3 and type(conditionList[0]) == int \
                                   and type(conditionList[1]) == int \
                                   and type(conditionList[2]) == int:
            self._conditionList = (conditionList,)     # 1-tuple
        else:
            self._conditionList = tuple(conditionList) # tuple for hashability
        
        self._original = original
        self._replacement = replacement

    # extractProperty is a function on tagged tokens that returns a value.
    # WARNING: The template and its rule type had better have the same implementation.
    def extractProperty (self, token):
        """
        Returns some property characterizing this token, such as its base lexical
        item or its tag.

        Each implentation of this method should correspond to an implementation of
        the method with the same name in a subclass of L{C{ProximateTokensTemplateI}}.

        @param token: The token
        @type token: Token
        @return: The property
        @rtype: any
        """
        assert False, "ProximateTokensRuleI is an abstract interface"

    def applyAt(self, tokens, positions):
        # Inherit docs from RuleI
        change = []
        for i in positions:
            if self.applies(tokens, i):
                change.append(i)

        for i in change:
            # replace the token with a similar one, except retagged
            tokens[i]['TAG'] = self._replacement
        
        return change

    def applies(self, tokens, index):
        # Inherit docs from RuleI
        # Does the target tag match this rule?
        if tokens[index]['TAG'] != self._original:
            return False
        
        # Otherwise, check each condition separately
        for (start, end, T) in self._conditionList:
            conditionOK = False
            # Check each token that could satisfy the condition
            for j in range(max(0, index+start), min(index+end+1, len(tokens))):
                if self.extractProperty(tokens[j]) == T:
                    conditionOK = True
                    break
            if not conditionOK:  # all conditions must hold
                return False

        return True

    def getOriginal(self):
        # Inherit docs from RuleI
        return self._original

    def getReplacement(self):
        # Inherit docs from RuleI
        return self._replacement

    def __eq__(self, other):
        return (other != None and \
                self._original == other._original and \
                self._replacement == other._replacement and \
                self._conditionList == other._conditionList)

    def __hash__(self):
        # Needs to include extractProperty in order to distinguish subclasses
        # A nicer way would be welcome.
        return hash( (self._original, self._replacement, self._conditionList,
                      self.extractProperty.func_code) )
    

class ProximateTagsTemplate(ProximateTokensTemplateI):
    """
    A template for generating L{ProximateTagsRule}s, which examine the tags of
    nearby tokens.  See superclass L{C{ProximateTokensTemplateI}} for details.
    """
    
    def __init__ (self, boundaryList):
        """
        @param boundaryList: The intervals in which tags are checked, relative to
            the position of the token that a generated rule is testing
        @type boundaryList: 2-tuple of int, or list of 2-tuple of int
        """
        ProximateTokensTemplateI.__init__(self, boundaryList, ProximateTagsRule)

    def extractProperty (self, token):
        """
        Returns the tag of a token.

        @param token: The token
        @type token: Token
        @return: The tag
        @rtype: any
        """
        return token['TAG']

class ProximateTagsRule (ProximateTokensRuleI):
    """
    A rule which examines the tags of nearby tokens.
    See superclass L{C{ProximateTokensRuleI}} for details.

    See also L{ProximateTagsTemplate}, which generates these rules.
    """

    def extractProperty (self, token):
        """
        Returns the tag of a token.

        @param token: The token
        @type token: Token
        @return: The tag
        @rtype: any
        """
        return token['TAG']

    def __str__(self):
        return "Replace %s with %s if %s" %(self._original, self._replacement,
                                    _strConditions(self._conditionList, "tagged "))

class ProximateWordsTemplate(ProximateTokensTemplateI):
    """
    A template for generating L{ProximateWordsRule}s, which examine the base types
    of nearby tokens.  See superclass L{ProximateTokensTemplateI} for details.
    """

    def __init__ (self, boundaryList):
        """
        @param boundaryList: The intervals in which base types are checked,
            relative to the position of the token that a generated rule is testing
        @type boundaryList: 2-tuple of int, or list of 2-tuple of int
        """
        ProximateTokensTemplateI.__init__(self, boundaryList, ProximateWordsRule)

    def extractProperty (self, token):
        """
        Returns the base type of a token.  For a corpus of tagged text, this
        corresponds to a word or lexical item.

        @param token: The token
        @type token: Token
        @return: The base type
        @rtype: any
        """
        return token['TEXT']

    # This template only looks at words, so replacing tokens won't change the
    # rules it generates.
    def getNeighborhood (self, tokens, index):
        # inherit docs from TemplateI
        return {index: None}

# a lexical rule
class ProximateWordsRule (ProximateTokensRuleI):
    """
    A rule which examines the base types of nearby tokens.
    See superclass L{C{ProximateTokensRuleI}} for details.

    See also L{ProximateWordsTemplate}, which generates these rules.
    """

    def extractProperty (self, token):
        """
        Returns the base type of a token.  For a corpus of tagged text, this
        corresponds to a word or lexical item.

        @param token: The token
        @type token: Token
        @return: The base type
        @rtype: any
        """
        return token['TEXT']

    def __str__(self):
        return "Replace %s with %s if %s" %(self._original, self._replacement,
                                            _strConditions(self._conditionList, ""))

def _strConditions (conditionList, tagged):
    # tagged is just an ad hoc string that differs between Words and Tags rules
    if len(conditionList) == 0:
        return "the sun rises in the east" # no conditions, always applies
    else:
        base = _strCondition(conditionList[0], tagged)
        for c in conditionList[1:]:
            base += ", and " + _strCondition(c, tagged)

    return base

def _strCondition (cond, tagged):
    (start, end, T) = cond  # T is the property checked by the condition
    if start > end:
        return "pigs fly" # condition can't be fulfilled
    
    elif start == end:
        if start == -1:
            return "the preceding word is %s%s" %(tagged, T)
        elif start == 1:
            return "the following word is %s%s" %(tagged, T)
        elif start < -1:
            return "the word %i before is %s%s" %(0-start, tagged, T)
        else: # start = 0 or start > 1
            return "the word %i after is %s%s" %(start, tagged, T)
    else:
        if end < 0:
            return "one of the %i preceding words is %s%s" %(end-start+1, tagged, T)
        elif start > 0:
            return "one of the %i following words is %s%s" %(end-start+1, tagged, T)
        else: # start <= 0 but end >= 0 -- an odd rule
            return "this word, or one of the %i preceding words, or one of the \
                    %i following words, is %s%s" %(end, end, tagged, T)


class SymmetricProximateTokensTemplate(TemplateI):
    """
    Simulates two L{ProximateTokensTemplateI}s which are symmetric across the
    location of the token.  For rules of the form "If the M{n}th token is tagged
    C{A}, and any tag preceding B{or} following the M{n}th token by a distance
    between M{x} and M{y} is C{B}, and ... , then change the tag of the nth token
    from C{A} to C{C}."

    One C{ProximateTokensTemplateI} is formed by passing in the same arguments
    given to this class's constructor: tuples representing intervals in which
    a tag may be found.  The other C{ProximateTokensTemplateI} is constructed
    with the negative of all the arguments in reversed order.  For example, a
    C{SymmetricProximateTokensTemplate} using the pair (-2,-1) and the
    constructor C{ProximateTagsTemplate} generates the same rules as a
    C{ProximateTagsTemplate} using (-2,-1) plus a second C{ProximateTagsTemplate}
    using (1,2).

    This is useful because we typically don't want templates to specify only
    "following" or only "preceding"; we'd like our rules to be able to look in
    either direction.
    """

    def __init__(self, boundaryList, proximateTokensTemplate):
        """
        @param boundaryList: Tuples representing how far from a token a rule
            may apply.  Do not pass arguments like [(-2,-1), (1,2)] which
            include symmetric pairs already; this may cause the template to
            generate redundant rules.
        @type boundaryList: 2-tuple of int, or list of 2-tuple of int
        @param proximateRuleType: A constructor for a subclass of
            C{ProximateTokensTemplateI}.
        @type proximateRuleType: function
        """
        self._ptt1 = proximateTokensTemplate(boundaryList)
        if len(boundaryList) == 2 and type(boundaryList[0]) == int \
                                  and type(boundaryList[1]) == int:
            self._ptt2 = proximateTokensTemplate((-1*boundaryList[1],
                                                  -1*boundaryList[0]))
        else:
            self._ptt2 = proximateTokensTemplate([(-1*b, -1*a)
                                                  for (a,b) in boundaryList])

    # Generates lists of a subtype of ProximateTokensRuleI.
    def makeApplicableRules (self, tokens, index, correctTag):
        """
        See L{TemplateI} for full specifications.

        @rtype: list of ProximateTokensRuleI
        """
        return self._ptt1.makeApplicableRules(tokens, index, correctTag) \
               + self._ptt2.makeApplicableRules(tokens, index, correctTag)

    def getNeighborhood (self, tokens, index):
        # inherit docs from TemplateI
        n = self._ptt1.getNeighborhood(tokens, index).copy()
        n.update(self._ptt2.getNeighborhood(tokens, index))
        return n
