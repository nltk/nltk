# Natural Language Toolkit: Hidden Markov Model
#
# Copyright (C) 2003 University of Melbourne
# Author: Trevor Cohn <tacohn@cs.mu.oz.au>
# URL: <http://nltk.sf.net>
# For license information, see LICENSE.TXT
#
# $Id$

"""
Hidden Markov Models (HMMs) largely used to assign the correct label sequence
to sequential data or assess the probability of a given label and data
sequence. These models are finite state machines characterised by a number
of states, transitions between these states, and output symbols emitted
while in each state. The HMM is an extension to the Markov chain, where each
state corresponds deterministically to a given event. In the HMM the
observation is a probabilistic function of the state. HMMs share the Markov
chain's assumption, being that the probability of transition from one state to
another only depends on the current state - i.e. the series of states that
led to the current state are not used. They are also time invariant.

The HMM is a directed graph, with probability weighted edges (representing the
probability of a transition between the source and sink states) where each
vertex emits an output symbol when entered. The symbol (or observation) is
non-deterministically generated. For this reason, knowing that a sequence of
output observations was generated by a given HMM does not mean that the
corresponding sequence of states (and what the current state is) is known. This
is the 'hidden' in the hidden markov model.

Formally, a HMM can be characterised by:
    - the output observation alphabet. This is the set of symbols which may be
      observed as output of the system. 
    - the set of states. 
    - the transition probabilities M{a_{ij} = P(s_t = j | s_{t-1} = i)}. These
      represent the probability of transition to each state from a given
      state. 
    - the output probability matrix M{b_i(k) = P(X_t = o_k | s_t = i). These
      represent the probability of observing each symbol in a given state.
    - the initial state distribution. This gives the probability of starting
      in each state.

To ground this discussion, take a common NLP application, part-of-speech
(POS) tagging. An HMM is desirable for this task as the highest probability
tag sequence can be calculated for a given sequence of word forms. This differs
from other tagging techniques which often tag each word individually, seeking
to optimise each individual tagging greedily without regard to the optimal
combination of tags for a larger unit, such as a sentence. The HMM does this
with the Viterbi algorithm, which efficiently computes the optimal path
through the graph given the sequence of words forms.

In POS tagging the states usually have a 1:1 correspondence with the tag
alphabet - i.e. each state represents a single tag. The output observation
alphabet is the set of word forms (the lexicon), and the remaining three
parameters are derived by a training regime. With this information the
probability of a given sentence can be easily derived, by simply summing
the probability of each distinct path through the model. Similarly, the
highest probability tagging sequence can be derived with the Viterbi
algorithm, yielding a state sequence which can be mapped into a tag sequence.

This discussion assumes that the HMM has been trained. This is probably the
most difficult task with the model, and requires either MLE estimates of the
parameters or unsupervised learning using the Baum-Welch algorithm, a variant
of EM.
"""

from nltk.probability import *
from Numeric import *

class HMM:
    """
    Based on HMM description in Chapter 8, Huang, Acero and Hon, Spoken
    Language Processing.
    """
    def __init__(self, symbols, states, transitions, outputs, priors):
        """
        Creates a hidden markov model parametised by the the states,
        transition probabilities, output probabilities and priors.

        @param  symbols:        the set of output symbols (alphabet)
        @type   symbols:        (seq) of any
        @param  states:         a set of states representing state space
        @type   states:         seq of any
        @param  transitions:    transition probabilities; Pr(s_i | s_j)
                                is the probability of transition from state i
                                given the model is in state_j
        @type   transitions:    C{ConditionalProbDistI}
        @param  outputs:        output probabilities; Pr(o_k | s_i) is the
                                probability of emitting symbol k when entering
                                state i
        @type   outputs:        C{ConditionalProbDistI}
        @param  priors:         initial state distribution; Pr(s_i) is the
                                probability of starting in state i
        @type   priors:         C{ProbDistI}
        """
        self._states = states
        self._transitions = transitions
        self._symbols = symbols
        self._outputs = outputs
        self._priors = priors

    def probability(self, symbols):
        """
        Returns the probability of the given symbol sequence. Uses the forward
        algorithm.
        """
        T = len(symbols)
        N = len(self._states)
        alpha = zeros((T, N), Float64)

        for t in range(T):
            symbol = symbols[t]
            if t == 0:
                for i in range(N):
                    state = self._states[i]
                    alpha[t, i] = self._priors.prob(state) * \
                                  self._outputs[state].prob(symbol)
            else:
                for i in range(N):
                    si = self._states[i]
                    for j in range(N):
                        sj = self._states[j]
                        alpha[t, i] += alpha[t-1, j] * \
                                       self._transitions[si].prob(sj)
                    alpha[t, i] *= self._outputs[si].prob(symbol)

        p = 0
        for i in range(N):
            p += alpha[T-1, i]

        return p

    def best_path(self, symbols):
        """
        Returns the state sequence of the optimal (most probable) path through
        the HMM. Uses the Viterbi algorithm.
        """
        T = len(symbols)
        N = len(self._states)
        V = zeros((T, N), Float64)
        #B = zeros((T, N), Int)
        B = {}

        for t in range(T):
            symbol = symbols[t]
            if t == 0:
                for i in range(N):
                    state = self._states[i]
                    V[t, i] = self._priors.prob(state) * \
                              self._outputs[state].prob(symbol)
                    B[t, state] = None
            else:
                for j in range(N):
                    sj = self._states[j]
                    best = None
                    for i in range(N):
                        si = self._states[i]
                        va = V[t-1, i] * self._transitions[si].prob(sj)
                        if not best or va > best[0]:
                            best = (va, si)
                    V[t, j] = best[0] * self._outputs[sj].prob(symbol)
                    B[t, sj] = best[1]

        #print 'V', V
        #print 'B', B

        best = None
        for i in range(N):
            val = V[T-1, i]
            if not best or val > best[0]:
                best = (val, self._states[i])

        #print 'best', best

        current = best[1]
        sequence = [current]
        for t in range(T-1, 0, -1):
            last = B[t, current]
            sequence.append(last)
            current = last

        sequence.reverse()
        return sequence

    def __repr__(self):
        return '<HMM %d states and %d output symbols>' \
                % (len(self._states), len(self._symbols))

class HMMTrainer:
    def __init__(self, states, symbols):
        """
        Creates an HMM trainer to induce an HMM with the given states and
        output symbol alphabet. A supervised and unsupervised training
        method may be used.
        """
        self._states = states
        self._symbols = symbols
        self._symbol_map = {}
        self._state_map = {}
        N = 0
        for state in states:
            if not self._state_map.has_key(state):
                self._state_map[state] = N
                N += 1

    def train_baum_welch(self, symbol_sequence):
        """
        Trains the HMM using the Baum-Welch algorithm to maximise the
        probability of the data sequence. This is a variant of the EM
        algorithm, and is unsupervised in that it doesn't need the state
        sequences for the symbols.

        FIXME - IMPLEMENTATION UNFINISHED
        """

        N = len(self._states)
        M = len(self._symbols)
        T = len(symbol_sequence)
        backward = zeros((T, N), Float64)
        forward = zeros((T, N), Float64)

        # create a (uniform) HMM, which will be iteratively refined
        A = ones((N, N), Float64) / float(N)
        B = ones((N, M), Float64) / float(M)
        pi = ones(N, Float64) / float(N)
        gamma = zeros((T, N, N), Float64)

        while True: # needs a condition here
            # E-step - compute auxilliary function Q
            # --------------------------------------

            # initialise the backward values
            for i in range(N):
                backward[T-1, i] = 1.0 / n

            # inductively calculate remaining backward values
            for t in range(T-2, 1, -1):
                x = self._symbol_map[symbols[t+1]] # if unseen?
                for i in range(n):
                    backward[t, i] = 0
                    for j in range(n):
                        backward[t, i] += A[i, j] * B[j, x] * backward[t+1, j]

            # calculate the forward values
            for t in range(T):
                symbol = symbols[t]
                x = self._symbol_map[symbol] # if unseen?
                if t == 0:
                    # initialise the forward values
                    for i in range(N):
                        forward[t, i] = pi[i] * B[i, x]
                else:
                    for i in range(N):
                        for j in range(N):
                            forward[t, i] += forward[t-1, j] * A[i, j]
                        forward[t, i] *= B[i, x]

            # calculate gamma values
            norm = 0
            for t in range(T):
                for i in range(N):
                    norm += forward[t, i]

            for t in range(1, T):
                x = self._symbol_map[symbols[t]] # if unseen?
                for i in range(N):
                    for j in range(N):
                        gamma[t, i, j] = forward[t-1, i] * A[i, j] * B[j, x] \
                                         * backward[t, j] / norm

            # calculate Q
            #hmmm ... this gets tricky

            # M-step - compute new A, B, pi values

    def train_supervised(self, symbol_sequences, state_sequences,
                         estimator=None):
        """
        Supervised training maximising the joint probability of the symbol and
        state sequences. This is done via collecting frequencies of
        transitions between states, symbol observations while within each
        state and which states start a sentence. These frequency distributions
        are then normalised into probability estimates, which can be
        smoothed if desired.

        @type estimator: function taking a C{FreqDist} and a number of bins
                         and returning a C{ProbDistI}
        """

        # default to the MLE estimate
        if estimator == None:
            estimator = lambda fdist, bins: MLEProbDist(fdist)

        # count occurences of starting states, transitions out of each state
        # and output symbols observed in each state
        starting = FreqDist()
        transitions = ConditionalFreqDist()
        outputs = ConditionalFreqDist()
        for symbols, states in zip(symbol_sequences, state_sequences):
            T = len(symbols)
            lasts = None
            for symbol, state in zip(symbols, states):
                if lasts == None:
                    starting.inc(state)
                else:
                    transitions[lasts].inc(state)
                outputs[state].inc(symbol)
                lasts = state

        # create probability distributions (with smoothing)
        N = len(self._states)
        pi = estimator(starting, N)
        A = ConditionalProbDist(transitions, estimator, N)
        B = ConditionalProbDist(outputs, estimator, len(self._symbols))
                               
        return HMM(self._symbols, self._states, A, B, pi)

class DictionaryConditionalProbDist(ConditionalProbDistI):
    def __init__(self, dict):
        self._dict = dict
    def __getitem__(self, condition):
        return self._dict[condition]
    def conditions(self):
        return self._dict.samples()

def demo():
    # example taken from page 381, Huang et al
    O = ['up', 'down', 'unchanged']
    omega = ['bull', 'bear', 'static']

    def pd(values, samples):
        d = {}
        for value, item in zip(values, samples):
            d[item] = value
        return DictionaryProbDist(d)

    def cpd(array, conditions, samples):
        d = {}
        for values, condition in zip(array, conditions):
            d[condition] = pd(values, samples)
        return DictionaryConditionalProbDist(d)

    A = array([[0.6, 0.2, 0.2], [0.5, 0.3, 0.2], [0.4, 0.1, 0.5]], Float64)
    A = cpd(A, omega, omega)
    B = array([[0.7, 0.1, 0.2], [0.1, 0.6, 0.3], [0.3, 0.3, 0.4]], Float64)
    B = cpd(B, omega, O)
    pi = array([0.5, 0.2, 0.3], Float64)
    pi = pd(pi, omega)

    model = HMM(symbols=O, states=omega, transitions=A, outputs=B, priors=pi)

    for test in [['up'] * 2, ['up'] * 5, ['up', 'down', 'up'], ['down'] * 5, 
                ['unchanged'] * 5 + ['up']]:
        print test, model.probability(test)
        print test, model.best_path(test)

def _split_tagged_tokens(tagged_tokens):
    from nltk.set import MutableSet
    from nltk.stemmer.porter import PorterStemmer
    words = []
    ws = []
    word_set = MutableSet()
    tags = []
    ts = []
    tag_set = MutableSet()
    stemmer = PorterStemmer()
    for token in tagged_tokens:
        for sub_token in token['SUBTOKENS']:
            w = sub_token['TEXT'].lower() # make them lower case
            #w = stemmer.stem_word(w) # oh, and stem them too
            #w = token.type().base()
            t = sub_token['TAG']
            word_set.insert(w)
            tag_set.insert(t)
            ws.append(w)
            ts.append(t)
            if t == '.':
                words.append(ws)
                ws = []
                tags.append(ts)
                ts = []

    return words, word_set.elements(), tags, tag_set.elements()

def demo_pos_supervised():
    from nltk.corpus import brown
    from nltk.tagger import TaggedTokenizer
    from sys import stdout
    print 'Loading data from Brown corpus...'
    tagged_tokens = []
    for item in brown.items()[:5]:
        tagged_tokens.append(brown.tokenize(item))
        
    words, word_set, tags, tag_set = _split_tagged_tokens(tagged_tokens)

    word_set.sort()
    tag_set.sort()

    print 'output alphabet', `word_set`[:50], '...'
    print 'state labels   ', `tag_set`[:50], '...'

    print 'Training HMM...'

    #print 'training data:'
    #print zip(words[1:], tags[1:])

    trainer = HMMTrainer(tag_set, word_set)
    hmm = trainer.train_supervised(words[100:], tags[100:],
                    lambda fd, bins: LidstoneProbDist(fd, 0.1, bins))

    print hmm
    print 'Testing...'
    
    for ws, ts in zip(words[:3], tags[:3]):
        print ws
        print 'HMM >>>'
        print hmm.best_path(ws)
        print 'CORRECT >>>'
        print ts
        print '-' * 60

    count = correct = 0
    for ws, ts in zip(words[:100], tags[:100]):
        print '.',
        stdout.flush()
        pts = hmm.best_path(ws)
        for t, pt in zip(ts, pts):
            count += 1
            if t == pt:
                correct += 1

    print 'accuracy over first', count, 'tokens %.1f' % (100.0 * correct / count)
    
if __name__ == '__main__':
    #demo()
    demo_pos_supervised()


