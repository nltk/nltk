%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Revised: Time-stamp: <2005-11-07 10:54:06 ewan>
% 
% $Log$
% Revision 1.1  2006/02/08 15:36:53  ehk
% First import of beamer.sty slides. Some files still need renaming.
%
% Revision 1.7  2005/11/08 16:31:37  ewan
% *** empty log message ***
%
% Revision 1.6  2005/11/07 09:57:50  ewan
% *** empty log message ***
%
% Revision 1.5  2005/11/03 10:38:47  ewan
% *** empty log message ***
%
% Revision 1.4  2005/11/03 10:06:32  ewan
% First cut
%
% Revision 1.3  2005/11/02 15:28:42  ewan
% *** empty log message ***
%
% Revision 1.2  2005/11/02 09:59:13  ewan
% *** empty log message ***
%
% Revision 1.1  2005/10/28 18:38:47  ewan
% *** empty log message ***
%
% Revision 1.1  2004/11/17 13:54:43  ewan
% *** empty log message ***
%
% Revision 1.1  2004/08/16 16:24:28  ewan
% *** empty log message ***
%
% Revision 1.1  2004/08/09 21:56:09  neilb
% move from teaching/modules/icl to teaching/courses/icl. No corrections done
%
% Revision 1.3  2003/11/17 12:02:54  ewan
% First import into CVS
%
% Revision 1.1  2003/10/14 15:23:23  ewan
% *** empty log message ***
%
% Revision 1.6  2002/11/12 10:09:52  ewan
% Version used for published slides
%
% Revision 1.5  2002/11/11 13:14:23  ewan
% Added slides for Top-down Depth-first search
%
% Revision 1.4  2002/11/11 12:07:20  ewan
% Added overlays for bottom-up search
%
% Revision 1.3  2002/11/11 09:46:47  ewan
% Added in overlay slides for Top-down parse search space
%
% Revision 1.2  2002/11/07 16:28:26  ewan
% *** empty log message ***
%
% Revision 1.1  2002/11/07 15:47:04  ewan
% Renamed from 05-2.tex
%
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Introduction to Parsing CFGs}
\author{Ewan Klein \newline \mbox{ }ewan@inf.ed.ac.uk\mbox{ }}
\date{ICL --- 3 November 2005}




\newcommand{\Rule}{\rule{\textwidth}{1pt}}
\newcommand{\SqB}[1]{[#1]}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\usepackage{fancybox}

\usepackage{color}
\usepackage{amsmath}
\usepackage{graphicx}

% Shading
\definecolor{light}{gray}{.80}
\newcommand{\Hilite}[1]{\colorbox{yellow}{#1}}
\newcommand{\Shade}[1]{\colorbox{light}{#1}}

\newcommand{\Em}[1]{\textcolor{red}{#1}}
\newcommand{\Dim}[1]{\textcolor{gray}{#1}}

\setlength{\parskip}{0in}
\setlength{\parindent}{0in}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% JM abbreviations
\def\tab{\hbox{\kern0.4in}}    %% Insert space (even at start of line)
\def\al{\\\tab}                %% Next line is indented
\def\nl{\\\tab\tab}            %% Next line is double-indented
\def\nnl{\\\tab\tab\tab}       %% Next line is triple-indented
\def\blob{$\diamondsuit\ \ $}  %% Itemization without all the spacing
\def\mysum{\begin{Huge}\mbox{$\Sigma$}\end{Huge}}
\def\myprod{\begin{Huge}\mbox{$\Pi$}\end{Huge}}
\def\rarrow{$\rightarrow\ \ $}  %% 

\newcommand{\elt}{{\,{\in}\,}}  %%%cuts down on spacing
\newcommand{\eq}{{\,{=}\,}}  %%%cuts down on spacing
\def\stimes{{\,\times\,}}       %%%cuts down on spacing

%% BNF grammars %pnorvig Mar 14 1994:
\newcommand{\bl}{\;}                   %A blank between BNF constituents
\newcommand{\bnf}[1]{{\it #1}}          %A BNF constituent
\newcommand{\bnfeq}{\ensuremath{\rightarrow}} % BNF arrow (separates LHS from RHS) 
\newcommand{\bnfreveq}{\ensuremath{\leftarrow}}      % Reverse BNF arrow
\newcommand{\bnft}[1]{\ensuremath{\boldmath \( #1 \)}} % A BNF terminal 
\newcommand{\bnfv}[1]{\bnf{#1}}         % A BNF terminal variable constituent
\newcommand{\bnfnull}{\bnft{\epsilon}}  % An empty BNF right-hand-side
\newcommand{\bnfor}{\ensuremath{\mid\bl}}            % A BNF disjunction
\newcommand{\dcg}{\Leftarrow_{dcg}}     % Obsolete!

\newcommand{\fhs}[3]{\frac{#1}{#2} #3}  % Filler, Hole, Semantics

\newlength{\maxfigwidth}
\setlength{\maxfigwidth}{\textwidth}
\addtolength{\maxfigwidth}{-8\fboxsep}
\addtolength{\maxfigwidth}{-8\fboxrule}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage{synttree}
\branchheight{5ex}

\input{../defs.sty}

\begin{document}

\frame{\titlepage}

\mode<article>{\section[Outline]{ICL/Intro to Parsing CFGs/2005-11-03}}
\mode<presentation>{
  \section[Outline]{}
}

\frame{\tableofcontents}

\section{What is Parsing?}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 1
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Review CFGs}


  \begin{itemize}
  \item Sets of terminals (either lexical items or parts of speech).
    
  \item Sets of non-terminals (the constituents of the language).
    
  \item Sets of rules (or `productions') of the form $A \rightarrow \alpha$, where $\alpha$
    is a string of zero or more terminals and non-terminals.
\end{itemize}

\term{Derives:}
\begin{itemize}
\item If grammar $G$ contains the rule $A \rightarrow \gamma$ and
  $\alpha A \beta$ is a string in $(N \cup \Sigma)^*$, then $\alpha A
  \beta$ \term{directly derives} $\alpha \gamma \beta$ in $G$: $\alpha A
  \beta \Rightarrow \alpha \gamma \beta$.
  \item $\stackrel{*}{\Rightarrow}$ (\term{derives}) is the reflexive,
    transitive closure of $\Rightarrow$; e.g., S
    $\stackrel{*}{\Rightarrow} \alpha$ if S
    $\stackrel{*}{\Rightarrow} \alpha_0$,  $\alpha_0
    \stackrel{*}{\Rightarrow} \alpha_1$, \ldots, $\alpha_n
    \stackrel{*}{\Rightarrow} \alpha$.
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 2
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\begin{frame}[fragile]
%  \frametitle{Examples}


%S $\rightarrow$ \NP \,\, \VP$

%\NP $\rightarrow$ \Det \,\, \Nom$ 

%$\Nom $\rightarrow$ Noun$ 

%\VP $\rightarrow$ V$

%\Det $\rightarrow$ a$ 

%Noun $\rightarrow$ flight$

%V $\rightarrow$ left$

%\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 3
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Parsing}


Assign a \Em{correct} tree to a string, given
a grammar $G$, i.e.,
\begin{itemize}
\item The leaves of the tree cover all and only the input.
\item The tree corresponds to a valid derivation according to $G$.
\item \scare{correct}: 
  \begin{itemize}
  \item means the tree is consistent with the input and the grammar;
  \item \textbf{doesn't} mean that it's the proper way to represent
    English in any general sense.
  \end{itemize}
\end{itemize}
\end{frame}

\begin{frame}[fragile]
  \frametitle{Declarative vs./ Procedural Knowledge}
\begin{itemize}
  \item CFGs are \Em{declarative}: they tell us \textbf{what} the
    well-formed structures and strings are.
  \item Parsers are \Em{procedural}: they tell us \textbf{how} to
    compute the structure(s) for a given string.
\end{itemize}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 4
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Parsing as Search}


Syntactic parsing can be viewed as a search (cf.\ Jurafsky \& Martin):

\begin{itemize}
% \item Regular Expression parsing:
%   \begin{itemize}
%   \item search space of all possible paths through the FSA;
%   \item search space defined by the FSA;
%   \item search is guided by the structure of the space and the input.
% \end{itemize}

  \item search space: all possible trees generated by the grammar;
  \item search space defined by the grammar;
  \item search guided by the structure of the space and the input.

\end{itemize}
\PropN\ $\rightarrow$ \ling{Houston} $\mid$ \ling{TWA}\\
\hline
\end{tabular}



\end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Slide 5
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Mini Grammar \& Lexicon}
\bigskip

\begin{tabular}{|p{15em}||l|}\hline
\Se\ $\rightarrow$ \NP\ \VP\ $\mid$ \Aux\ \NP\ \VP\ $\mid$  \VP  & 
\Det\ $\rightarrow$ \ling{that} $\mid$ \ling{this} $\mid$ \ling{a} \\
\NP\ $\rightarrow$ \Det\ \Nom\  $\mid$ \PropN & 
\N\ $\rightarrow$ \ling{book} $\mid$ \ling{flight} $\mid$ \ling{meal}\\
\Nom\ $\rightarrow$ \Nom\ \PP\  $\mid$ \N\ \Nom & 
\V\ $\rightarrow$ \ling{book} $\mid$ \ling{include} $\mid$ \ling{prefer}\\
\PP\ $\rightarrow$ \Prep\ \NP & 
\Aux\ $\rightarrow$ \ling{does} \\
\VP\ $\rightarrow$ \V\ $\mid$  \V\ \NP & 
\Prep\ $\rightarrow$ \ling{from} $\mid$ \ling{to} $\mid$ \ling{on}\\
\Nom\ $\rightarrow$ \N\ \PP\ $\mid$  \N\ \Nom  & 
\PropN\ $\rightarrow$ \ling{Houston} $\mid$ \ling{TWA}\\
\hline
\end{tabular}



\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 6
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Example Parse Tree}

The parse of the sentence \ling{Book that flight} using the 
mini grammar and lexicon
\begin{center}


\synttree[S 
             [VP [V [\ling{Book}]]
             [NP [Det [\ling{that}]]
                 [Nom [N [\ling{flight}]]]]]
          ]
 
\end{center}

\end{frame}

\section{Parsing Strategies}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 7
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Parsing}

What kind of constraints can be used to connect the grammar
 and our example sentence when searching for the parse tree?

\begin{itemize}
\item top-down (goal-directed) strategy:
  \begin{itemize}
  \item e.g., tree should have one root (grammar constraint)
  \end{itemize}

\item bottom-up (data-driven) strategy:
  \begin{itemize}
  \item e.g., tree should have 3 leaves (input sentence constraint)
  \end{itemize}
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{A Note on the Input}

We assume the following:

\begin{itemize}
\item The input is not tagged.
\item The input consists of unanalyzed word tokens.
\item e words in the input are 'known' (i.e., are leaves of lexical
rules in grammar).
\item All the words in the input are available simultaneously (i.e.,
  they're buffered).
\end{itemize}

\end{frame}

\subsection{Top-Down}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 9
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Top-Down Parsing}

  \begin{itemize}
  \item When the search is primarily goal- or expectation-driven (by
    the structure of the grammar), we're doing a top-down search.
  \item Primary goal is to find a tree rooted at \Se\ that derives the
    input string.
  \item Trees are built from the root node \Se\ to the leaves.
  \item NLTK-Lite demo of Recursive Descent parser\\
\begin{verbatim}
>>> from nltk_lite.draw.rdparser import demo
>>> demo()
\end{verbatim}
  \end{itemize}





\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 10
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\subsection{Bottom-Up}

\begin{frame}[fragile]
  \frametitle{Bottom-Up Parsing}

  \begin{itemize}
  \item When the search is primarily data-driven (by the input
    string), we're doing a \term{bottom-up} search.
  \item The primary consideration here is that all of the sub-trees of
    the final tree must hook up with the start symbol.
  \item NLTK-Lite demo of 
Shift-Reduce parser\\
\begin{verbatim}
>>> from nltk_lite.draw.srparser import demo
>>> demo()
\end{verbatim}
  \end{itemize}




\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 12
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



\begin{frame}[fragile]
  \frametitle{Search Control Issues}


Some parameters still need to be made explicit:
\begin{itemize}
\item non-parallel strategies (e.g., depth-first vs.\ breadth-first);
\item which node in the tree to expand next (e.g., leftmost);
\item which of the applicable grammar rule to try (e.g., order in the
  grammar)
\end{itemize}



\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 15
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Top-Down vs.~Bottom-Up}


There are advantages and disadvantages to both.

\term{Top-Down}: 
\begin{itemize}
\item only searches in the space of `reasonable' answers;
\item suggests hypotheses that are not consistent with the input string;
\item has problems with left-recursion (covered later).
\end{itemize}

\term{Bottom-Up}
\begin{itemize}
\item only forms hypotheses consistent with the input strings; 
\item suggests hypotheses that make no sense `globally'.
%\item also has problems with infinite spaces.
\end{itemize}

\end{frame}

\section{Left Corner Parsing}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 16
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{A Hybrid Approach}


  \begin{itemize}
    
  \item Neither top-down nor bottom-up adequately exploit all the
    constraints.
  \item There are many way to combine top-down expectations with bottom-up
    data to get a more efficient search.
  \item The most popular methods use one method as the basic search control
    strategy to generate trees, and
  \item then use constraints from the other method to dynamically
    filter out ``bad'' structures.
  \item Example: top-down parsing with bottom-up filtering.
\end{itemize}
 
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 17
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Left Corner Parsing}

  \begin{itemize}
  \item Consider a top-down parser parsing the following input: 
\begin{quote}
  \ling{Will this flight arrive on time?}
\item Assume that the grammar contains the following $S$ rules:
\end{quote}
\begin{quote}
  \Se $\rightarrow$ \NP \,\, \VP
  
  \Se $\rightarrow$ \Aux \,\, \NP \,\, \VP
  
  \Se $\rightarrow$ \VP
\end{quote}

\item \Em{Left-Corner Observation}: in a successful parse, the current
input word is first in the derivation of the unexpanded node.

  \end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 18
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Left Corners}
  
  

%\term{Left­Corner} of a tree:
\begin{itemize}
%\item The \term{left corner} of a CFG rule is the leftmost symbol on the
%  RHS.

\item A category $B$ (terminal or non-terminal) is a \term{left corner} of a
  tree rooted in $A$ if $A$ derives $B\alpha$.
\item Left corners for each non-terminal in our mini-grammar:\\
\mbox{}\\
\begin{tabular}[t]{|c|l|} \hline
\textit{Category} & \textit{Left Corners} \\ \hline
\Se      & \Det, Proper-Noun, \Aux, \V \\
\NP       & \Det, Proper-Noun \\
\Nom  & \N \\
\VP       & \V \\ \hline
\end{tabular} 
\end{itemize}



\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 19
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Left Corners, 2}


\synttree[VP
           [\Em{V} [\Em{\ling{prefer}}]]
           [NP [Det [\ling{a}]]
               [A [\ling{early}]]
               [Nom [N [\ling{flight}]]]
           ]
         ]

\bigskip
\begin{itemize}
\item \V\ and \ling{prefer} are both left-corners of the tree rooted in \VP.
\item Filtering with left corners:
  \begin{itemize}
  \item \textit{Only consider an expansion if  current input can serve as
the left-corner of that expansion.}
  \end{itemize}
\end{itemize}
\end{frame}

\section{Problems}

\subsection{Left Recursion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 21
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Left Recursion}


In top-down, depth-first, left-to-right parsers, a left recursive
 grammar can cause the search to never terminate.

\begin{itemize}
  \item $A \rightarrow A \beta$
\begin{quote}
  \Nom\ $\rightarrow$ \Nom \; \PP
  
  \VP\ $\rightarrow$ \VP \; \PP
  
  \Se\ $\rightarrow$ \Se \; and \; \Se
\end{quote}

%\item $A$ derives $\alpha A \beta$ and $\alpha$ derives $\epsilon$
%  (i.e., the grammar contains a non-terminal that contains itself
%  anywhere along its leftmost branch)
\item $A$ derives $A \beta$ 
  (i.e., the grammar contains a non-terminal that contains itself
  anywhere along its leftmost branch)
\begin{quote}
  \NP $\rightarrow$ \NP $_\text{poss}$ \; \Nom
  
  \NP $_\text{poss}$ \ $\rightarrow$ \NP \, \ling{'s}
\end{quote}
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 22
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Left Recursion, cont.}

  \begin{itemize}
  \item Demo example:\\
    \Nom $\rightarrow$ \Nom \; \PP
  \end{itemize}




Some (poor) solutions:
\begin{itemize}
\item Rewrite the grammar to a weakly equivalent one (how?)
  \begin{itemize}
  \item might not get a correct or useful parse tree.
  \end{itemize}
\item Limit the depth during search
  \begin{itemize}
  \item limit is arbitrary.
  \end{itemize}
\end{itemize}

\end{frame}

\subsection{Ambiguity}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 23
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Ambiguity}

Given a grammar, \term{Global Ambiguity} potentially leads to
multiple parses for the same input (if we force it to). 
\begin{quote}
  \ling{I saw a woman with a telescope.}
\end{quote}

\term{Local Ambiguity}, in contrast, leads to hypotheses that are
locally reasonable but eventually lead nowhere and result
in inefficient backtracking. Filtering helps a little. 
\begin{quote}
  \ling{Book that flight.}
\end{quote}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 24
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Common Structural Ambiguities}

  \begin{itemize}
  \item See this week's Lab Exercises.
  \end{itemize}



\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 27
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Why is Ambiguity Problematic?}

  \begin{itemize}
  \item There are potentially an exponential number of parses for
a sentence.
\begin{itemize}
\item Returning all structurally valid parses isn't
always a good idea.
\end{itemize}
\item Some solutions:
\begin{itemize}
\item exploit regularities in the search space to derive common subparts
  only once;
\item heuristic search strategies;
\item incorporate semantics into the disambiguation process.
\end{itemize}
  \end{itemize}




\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 28
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{frame}[fragile]
%   \frametitle{Common substructures}


% Despite all this ambiguity and backtracking there are commons substructures to be
% taken advantage of.

% Consider parsing the following \NP:
% \begin{quote}
%   \ling{a flight from Indianapolis to Houston on TWA}
% \end{quote}
% with the following rules:
% \begin{quote}
%   \NP\ $\rightarrow$ \Det \,\, \Nom 

%   \NP\ $\rightarrow$ \NP \,\, \PP 
  
%   \NP\ $\rightarrow$ Proper-Noun
% \end{quote}
% What happens with a top-down parser?

% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Slide 29
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{frame}[fragile]
  
% \Dfps
% \pstree{\TR{NP}}{
%   \skiplevels{1}
%   \lextree{Det}{\ling{a}}\endskiplevels
%   \pstree{\TR{Nom}}{
%     \pstree{\TR{N}}{\Tr[ref=l]{\ling{flight from Indianopolis to Houston on TWA}}}
%   }
% }

% \medskip

% \pstree{\TR{NP}}{ 
%     \pstree{\TR{NP}}{
%       \skiplevels{1}
%       \lextree{Det}{\ling{a}}\endskiplevels
%       \pstree{\TR{Nom}}{
%         \pstree{\TR{N}}{\Tr{\ling{flight}}}
%       }
%     }
%     \pstree{\TR{PP}}{
%       \skiplevel{
%         \lextree{P}{\ling{from}}}
%       \pstree{\TR{NP}}{
%           \pstree{\TR{Prop-N}}{
%           \Tr[ref=l]{\ling{Indianopolis to Houston on TWA}}}
%       }
%     }
% }
  

% \end{frame}

% \begin{frame}[fragile]
% \vspace{3ex}
% \Dfps
% \pstree{\TR{NP}}{  
%   \pstree{\TR{NP}}{ 
%     \pstree{\TR{NP}}{
%       \skiplevels{1}
%       \lextree{Det}{\ling{a}}\endskiplevels
%       \pstree{\TR{Nom}}{
%         \pstree{\TR{N}}{\Tr{\ling{flight}}}
%       }
%     }
%     \pstree{\TR{PP}}{
%       \skiplevel{
%         \lextree{P}{\ling{from}}}
%       \pstree{\TR{NP}}{
%         \pstree{\TR{Prop-N}}{
%           \Tr{\ling{Indianopolis}}}
%       }
%     }
%   }
%     \pstree{\TR{PP}}{
%       \skiplevel{
%         \lextree{P}{\ling{to}}}
%       \pstree{\TR{NP}}{
%         \pstree{\TR{Prop-N}}{
%           \Tr[ref=l]{\ling{Houston on TWA}}}
%       }
%     }


% }

% \end{frame}

% \begin{frame}[fragile]

% \vspace{3ex}
% {\small
% \Dfps
% \pstree{\TR{NP}}{  
%   \pstree{\TR{NP}}{  
%     \pstree{\TR{NP}}{ 
%       \pstree{\TR{NP}}{
%         \skiplevels{1}
%         \lextree{Det}{\ling{a}}\endskiplevels
%         \pstree{\TR{Nom}}{
%           \pstree{\TR{N}}{\Tr{\ling{flight}}}
%         }
%       }
%       \pstree{\TR{PP}}{
%         \skiplevel{
%           \lextree{P}{\ling{from}}}
%         \pstree{\TR{NP}}{
%           \pstree{\TR{Prop-N}}{
%             \Tr{\ling{Indianopolis}}}
%         }
%       }
%     }
%     \pstree{\TR{PP}}{
%       \skiplevel{
%         \lextree{P}{\ling{to}}}
%       \pstree{\TR{NP}}{
%         \pstree{\TR{Prop-N}}{
%           \Tr{\ling{Houston}}}
%       }
%     }
%   }
%   \pstree{\TR{PP}}{
%     \skiplevel{
%       \lextree{P}{\ling{on}}}
%     \pstree{\TR{NP}}{
%       \pstree{\TR{Prop-N}}{
%         \Tr{\ling{TWA}}}
%     }
%   }
% }

% }
% \end{frame}

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% % Slide 30
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \begin{frame}[fragile]
%   \frametitle{Reuse via Dynamic Programming}


% Our current algorithm builds valid trees, discards them during
% backtracking, then rebuilds them


% \begin{itemize}
% \item the subtree for \ling{a flight} was derived 4 times!
% \end{itemize}

% %\term{Dynamic programming} is one answer to problems that have
% %sub-problems that get solved again and again

% We want an algorithm that fills a table with solutions to
% sub­problems that:
% \begin{itemize}
% \item does not do repeated work;
% \item does top-down search with bottom-up filtering;
% \item solves the left-recursion problem.
% %\item solves an exponential problem in $O(N^3)$ time
% \end{itemize}



% \end{frame}

\section{Summary}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Slide 31
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
  \frametitle{Summary}

  \begin{itemize}
  \item Important parsing concepts:
    \begin{itemize}
    \item Top-down vs. \ Bottom-up strategies
    \item Examples of each:
      \begin{itemize}
      \item Recursive Descent
      \item Shift-Reduce
      \end{itemize}
    \item Backtracking
    \item Global vs.\ Local Ambiguity
    \end{itemize}
  \end{itemize}
  
\end{frame}


\begin{frame}[fragile]
  \frametitle{Reading}

  \begin{itemize}
    \item Jurafsky and Martin Chapter 10
    \item NLTK Parsing Tutorial 
  \end{itemize}

\end{frame}






%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: "parse-lec"
%%% End: 
