===========================
Classifiers
===========================

# Package Structure
    nltk_lite
	|
	|--------> contrib 
			|
			|-------> classifier <all python source code goes in here>
			|
			|-------> classifier_tests <all pyunit tests go in here>


# Building the Project
     The project is built as a part of the setup script in nltk_lite


# Running Tests
     All tests can be run using the shell script run_tests.sh in classifier_tests package or the following command could be executed to do the same.
	python <...>/nltk_lite/contrib/classifier_tests/alltests.py


# Using the classifiers from shell/command prompt
     All classifiers take in a training file(*.data) and a *.names file. The two basic tasks a classifier is capable of performing are test and verify. 
When testing the classifier looks for a test(*.test) file and classifies the test data based on its learning from the training data. The output of this classification is printed out on the console. 
While verifying, the classifier looks for the gold(*.gold) file and classifies it similar to the test instances, the only difference being the evaluation post classification.

The classifiers are invoked from a launcher class <...>/nltk_lite/contrib/classifier/classify.py. Currently the input files are assumed to be in C4.5 format. Input file paths can be specified to the classifier in two different ways 

Method 1: All files, training(*.data), test(*.test) and gold(*.gold) files are assumed to have the same file name with different extensions. The common name is to be specified with the -f option. Without combining this option with any other modifier, the classifier will try to search for a <common_name>.data and <common_name>.test file in the path specified and perform the test operation. When combined with the -v option, the classifier will perform a verify operation.
	python <...>/nltk_lite/contrib/classifier/classify.py -a <algorithm> -f <path/common_name>
			the files to be present are path/common_name.names, path/common_name.data and path/common_name.test.
	python <...>/nltk_lite_contrib/classifier/classify.py -a <algorithm> -vf <path/common_name>
			the files to be present are path/common_name.names, path/common_name.data and path/common_name.gold.

Method 2: All the files are specified explicitly without their extensions.
	python <...>/nltk_lite/contrib/classifier/classify.py -a <algorithm> -t <path/training_name> -T <path/test_name>
			the files to be present are path/training_name.names, path/training_name.data and path/test_name.test.
	python <...>/nltk_lite/contrib/classifier/classify.py -a <algorithm> -t <path/training_name> -g <path/gold_name>
			the files to be present are path/training_name.names, path/training_name.data and path/gold_name.gold.

After the classifying the data, Accuracy and F-score measurements are printed automatically, but could be omitted by including the parameters -A and -F respectively during invocation. All other performance measures are printed when specified in the argument list. Multiple arguments can be passed to obtain measurements as shown below.
	python <...>/nltk_lite/contrib/classify.py -vprf datasets/minigolf/weather
		prints Accuracy, F-score, Precision and Recall using the minigolf/weather dataset and a One R classifier.
For more help on usage you can try:
	python <...>/nltk_lite/contrib/classifier/classify.py --help
