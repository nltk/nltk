###############################################################
###             NLTK: Installation Instructions             ###
###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~###
### Copyright (C) 2001 University of Pennsylvania           ###
### Author: Edward Loper <edloper@gradient.cis.upenn.edu>   ###
### URL: <http://nltk.sf.net>                               ###
### For license information, see LICENSE.TXT                ###
###############################################################

Requirements
~~~~~~~~~~~~
    Python
    ~~~~~~
    The natural language toolkit requires Python 2.1 or higher.  To
    check what version of Python you are running, run:
        % python -V

    Alternatively, run an interactive Python installation session, and
    check which version it reports.

    You can download the latest version of Python from:
        <http://www.python.org/download>
    or:
        <http://sourceforge.net/project/showfiles.php?group_id=5470>
    or:
        <http://www.python.org/2.1.1/rpms.html>

    Other Packages
    ~~~~~~~~~~~~~~
    The natural language toolkit makes use of several other open
    source Python packages.  These packages are not required to use
    much of Python's core functionality.  However, without them you
    won't be able to use some features (such as visualization).  The
    following packages are currently used by the natural langauge
    toolkit:

        - Tkinter ("Tk interface"): the standard Python interface to
          the Tk GUI toolkit.  This is usually installed by default
          under Windows, but you may need to install it separately
          if you are using Unix or a Macintosh.  Tkinter should be 
          included in your version of Python.  A RedHat 7.1 RPM is
          also available:
            <http://www.python.org/2.1.1/rpms.html>
        - Numeric: adds a fast array facility to the Python language. 
            <http://numpy.sf.net>
            <http://sourceforge.net/project/showfiles.php?group_id=1369>
        - Scientific Python: a collection of Python modules that are
          useful for scientific computing; we use it for plotting
          graphs.
            <http://starship.python.net/crew/hinsen/scientific.html>
 
    The following are packages that we are considering using in the
    future:

        - PyWordNet: a python interface to WordNet.  Wordnet is a
          lexcial databse, developed at Princeton University.
            <http://pywordnet.sf.net>
            <http://sourceforge.net/project/showfiles.php?group_id=27422>
          The WordNet database files can be downloaded from:
            <http://www.cogsci.princeton.edu/~wn/>

Windows Installation
~~~~~~~~~~~~~~~~~~~~
    After you have installed Python, run the nltk installation file
    (nltk-??.??.win32.exe).  The installation wizard will guide you
    through the installation process.

    Upgrading
    ~~~~~~~~~
    When upgrading the version of nltk you are using, the installation
    wizard will ask you if you wish to overwrite the old nltk files.
    Answer "yes."

RPM Installation
~~~~~~~~~~~~~~~~
    If you are running RedHat 7.1 (or a compatible system), you can
    install nltk from the RPM:

        % rpm -i nltk-??.??-1.noarch.rpm

    If you wish to build an RPM for nltk on a system other than RedHat
    7.1, you can use the SRPM:

        % rpm --rebuild nltk-??.??-1.noarch.rpm

Unix Installation
~~~~~~~~~~~~~~~~~
    You can manually install the toolkit from the .tar.gz file:

        gunzip nltk-??.??.tar.gz 
        tar -xvf nltk-??.??.tar
        cd nltk-??.??
        python setup.py install

    You can also manually install the toolkit from the .zip file:

        unzip nltk-??.??.zip
        cd nltk-??.??
        python setup.py install

Macintosh Installation
~~~~~~~~~~~~~~~~~~~~~~
    I have not tested nltk on a Macintosh; but I've been told that it
    works.  I do not know the details of installing packages on
    Macintoshes.  However, I belive that the procedure would be
    similar to the unix installation procedure (i.e., call setup.py
    with the "install" argument)

Corpora
~~~~~~~
    When learning how to process text, it is very useful to have some
    test corpera to play with.  The following list gives the locations
    where some text copora can be found:

    - The Brown Corpus      <http://www.hit.uib.no/icame/newcd.htm>
    - Penn Treebank Corpus  <http://www.cis.upenn.edu/~treebank/>
    - Project Gutenburg     <http://promo.net/pg/>
