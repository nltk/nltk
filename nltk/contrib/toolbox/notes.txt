1. Background
o-------------
The package nltk.contrib.shoebox contains functionality for manipulating Shoebox
files. These come in two types: settings files and database files. Database files are
either lexicon databases or text databases.


2. Levels
---------
The Shoebox functionality consists of three levels:

Level 1 -- The lowest level of functionality. It simply parses fields of a Shoebox file.
           Doesn't pay any attention to file type (setting vs. database, lexicon vs. text 
           database). In other words, Level 1 only knows about Standard Format.

Level 2 -- A higher level of functionality which recognizes file types. Level 2 functionality
           is divided into two modules to reflect the three main file types: settings, 
           lexicon, and text.

Level 3 -- The highest level of fucntionality which is capable of unifying settings 
           information with database contents.

Level 1 functionality already exists in the shoebox module. There is Steve's original
code (from corpora.shoebox) and Greg's code. Level 2 and 3 functionality exists, but is
patchy. The lexicon modules has two co-existing ways object models: one using a LexiconParser 
class (with Steve's low-level functionality) and another using a Lexicon class with a parse()
method (with Greg's low-level functionality). The former is being phased out in favor of the latter.
The current Level 2 functionality will probably be replaced by a more sophisticated hierarchical
approach advocated by Greg.

Standard Format, like XML, can have two levels of "goodness", *well-formed* and *valid*:

* **well-formed** Shoebox files merely conform to Standard Format
* **valid** Shoebox files are well-formed and conform to their associated settings files (metadata)

Well-formedness is therefore a necessary (but not sufficient) condition for validity.


3. Functionality Desiderata
---------------------------
Greg points out that there are at least 4 things we want our Shoebox functionality to do:

1. *Error Reporting* 
This means keeping track of
line numbers. I think this implies we need a class rather than a
function so we can access the line number if there is an error. If we
did use a function we would have to use a global variable or pass the
line number out with the return parse. A class seems a cleaner solution
to me. My higher level code will report syntax errors in shoebox records
and having a line number is extremely helpful. This should be useful for
Stuart's validation code too. Also I have too often found problems with
invalid utf8 sequences coming out of toolbox and fixing them requires
the use of a text editor and knowing the line number.

2. *Encodings* 
My dictionary data uses GBK encoding. My code currently 
assumes that the files have a uniform encoding but toolbox actually allows 
files to have two encodings. Languages can be specified to have a unicode 
encoding (this means utf8 to toolbox). All other languages will use the 
system codepage. I think this means passing the name of the files non-utf8 
encoding and a set containing the names of markers that use unicode to 
the routine that does the conversion. Also we should retain the option of 
ignoring the encoding so that something else could be done.

3. *Round Tripping* 
It is very useful to be able to write filters (in the
classic Unix sense) for standard format files. I want to be able to
modify just one aspect of a standard format file and leave all the rest
unchanged and have this simple to do. For example change the name of a
marker. This means we need to be very careful about preserving white
space. I have a nice routine that pretty prints my dictionary files. It
puts blank lines between sections of entries and reorders the fields in
a particular section of the entry. I don't mess with the linebreaking as
I want to use diff to check that there are no bugs in the filter code.

4. *Data Applications* 
This is quite different behaviour to the round 
tripping. In this kind of application I
don't want to preserve the line breaks, or trailing white space on
fields. This makes it simpler to test the value contained in a field.
This is important for validation, e.g. testing you don't have two
homonyms with the same homonym numbers, or senses with the same sense
numbers, or missing numbers etc.


4. Issues
---------
There are a number of unresolved issues.

1. *Uniqueness*
Shoebox does not impose any sort of uniqueness on entries but users may
want to have tools for validating it.

2. *Standards*
Shoebox users differ widely in the way that they use Shoebox. We need to see
what sort of standards exist (e.g., MDF) and see to what extent people's data
conforms to these standards.


5. Bugs
-------
* Font information for markers ignored
* File sets, jump sets, templates, and (RTF) export sets ignored
* Interlinearized texts do not always parse properly (\id in metadata, but \ref is actual head field)


6. TODO
-------
* tutorial
* extensive unit-tests
* more comprehensive handling of encodings
* error handling model
* interlinearized texts


