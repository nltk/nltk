.. Copyright (C) 2001-2014 NLTK Project
.. For license information, see LICENSE.TXT

====================
 Processing Twitter
====================


Overview
========

Although there is widespread interest in processing and analysing
Twitter data, restrictions imposed by Twitter make it awkward to use
standard NLP approaches for storing and distributing reusable tweet
corpora. More specifically, according to Twitter's `Terms of Service <https://dev.twitter.com/terms/api-terms>`_:

	 If you provide downloadable datasets of Twitter Content or an
	 API that returns Twitter Content, you may only return IDs
	 (including Tweet IDs and user IDs).

This is motivated, at least in part, by the need to honour
the right of users to delete their tweets; deletion would not be truly
possible if the tweets in question survived in corpora redistributed
by third parties.

Consequently, it is not possible for NLTK to include a corpus of
Tweets within its collection of downloadable resources. However, we
can adopt the standard
workaround [McReadie21012]_ of distributing a corpus of Tweet IDs, and leave
it to individuals to retrive the full Tweets corresponding to those
IDs. Although this is a workable alternative, it should be be borne in
mind that there are two potential problems:

* The reconstructed corpus is not guaranteed, or even likely, to be
  identical to the original Tweet corpus, due to Tweets having been deleted
  in the intervening time.

* If the corpus is large, then Twitter's rate limiting policy might
  make the process of reconstructing the corpus excessively
  time-consuming. 

Twitter Client
==============

In order to gain access to the Twitter API, it is necessary to first
register your application with
`<https://dev.twitter.com/apps>`_. There are two main options. OAuth 1
is for user authenticated API calls, and allows sending status
updates, etc, whereas OAuth 2 is for application authenticated calls,
where read-only access is sufficient. Although OAuth 2 sounds more
appropriate for the kind of tasks envisaged within NLTK, it turns out
that access to Twitter's streaming API requires OAuth 1, so the
following discussion assumes that after logging into Twitter via a
user account, you have obtained **Read and Write**
access for your application (as specified on the *Permissions* tab of
Twitter's Application Management screen). This will give you four
distinct keys, which you should store in a text file with the
following structure::

  API key=YOUR API KEY
  API secret=YOUR API SECRET
  Access token=YOUR ACCESS TOKEN
  Access token secret=YOUR ACCESS TOKEN SECRET

By default, this data will looked for in a file `credentials.txt`
located in ...

.. note:: `credentials.txt` is currently expected to be in the same directory as
  `twitterclient.py`, but looking for it in a user directory would
  make more sense. Maybe via an env variable?

The module `nltk.misc.twitterclient` is a wrapper around a third party Python
Twitter client, namely `Twython
<https://pypi.python.org/pypi/twython>`_. Although there are a number
of Python packages for calling the Twitter API, I chose Twython on the
basis of its functionality, Python 3 support, and `good documentation <https://twython.readthedocs.org>`_.

The following example illustrates taking the API keys from a file, and
passing them to the streaming client class `Streamer`.

>>> from nltk.misc.twitterclient import authenticate, Streamer,  TweetHandler
>>> oauth = authenticate('/Users/ewan/twitter/credentials.txt') 
>>> client = Streamer(**oauth)

The authentication steps are the same when using `Query`, a class
which wraps calls to Twitter's REST API. 

When Tweets are received, via either the streaming or the REST API,
they can be passed to the terminal for casual inspection or stored in
one or more files. (In principle, they could also be stored in a
database, though this has not been implemented yet.) The methods for
dealing with Tweets are provided by the `TweetHandler` class, which
takes the relevant client instance as an initialisation
parameter. Initialisation can also set a limit to the number of Tweets
received (e.g., ``limit=10``). The API endpoint ``statuses.sample()``
returns at most a 1% sample of the public Twitter stream [Morstatter2013]_. 
        
>>> handler = TweetHandler(client, limit=10)
>>> method = handler.stdout
>>> client.register(method)
>>> client.statuses.sample() # doctest: +SKIP
Be alright #MTVHottest Justin Bieber
RT @PriceRunner: RT to show your support for the Brits at the #CommonwealthGames @weRengland @TeamWales @Team_Scotland @Glasgow2014
iki yÃ¼zlÃ¼ dostlar :)
@colgadosfutbol Ni en Vallecas hizo nada
I do have a period of time when I do dream of the girls like every night but then I have another period of time without, &amp; I'm in that rn.
Wag mo na kase ipagsiksikan sarili mo boy.
I wish I can Vote TT _ TT #ì¸í”¼ë‹ˆíŠ¸
RT @Engabdallahelha: Ø§Ù†Ø§ Ù‚Ù„ÙŠÙ„ Ø§Ù„ÙƒÙ„Ø§Ù…... ÙˆØ¯Ù‡ Ø¨ÙŠØ®Ù„ÙŠ Ø§Ù„Ù†Ø§Ø³ ØªØ®Ø§Ù Ù…Ù†ÙŠ
Hi @JaiBrooks1 !ğŸ·How are you sunshine?â˜€Pls, follow @rockingchadwick !ğŸ˜„She loves you so much!ğŸ˜ğŸ˜˜â™¥(DON'T IGNORE THAT TWEET) ğŸ˜¡ğŸ˜¡x32
RT @ka3am_al3ayel: @Bander65861835 http://t.co/qP9vuhIac5



NLTK support for Twitter processing is intended the following cases:

* building a corpus of Tweets



.. [McReadie21012]Richard
   McCreadie, Ian Soboroff, Jimmy Lin, Craig Macdonald, Iadh Ounis and
   Dean McCullough (2012) *On Building a Reusable Twitter Corpus*
   `PDF <http://www.dcs.gla.ac.uk/~craigm/publications/mccreadie12tweets.pdf>`__

.. [Morstatter2013] Fred Morstatter, Juergen Pfeffer, Huan Liu and Kathleen
   M. Carley (2013)
   *Is the Sample Good Enough? Comparing Data from Twitterâ€™s
   Streaming API with Twitterâ€™s Firehose*
   `PDF <http://www.public.asu.edu/~fmorstat/paperpdfs/icwsm2013.pdf>`__

