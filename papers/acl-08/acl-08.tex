% $Rev%\documentclass[11pt]{article}\usepackage{acl08}\usepackage{times}\usepackage{latexsym}\usepackage{epsfig,url}\newcommand{\NLP}{\textsc{nlp}}\newcommand{\NLTK}{\textsc{nltk}}\setlength\titlebox{6.5cm}    % Expanding the titlebox\title{Multidisciplinary Instruction with the Natural Language Toolkit}\author{}% \author{Joakim Nivre \\%   School of Mathematics and Systems Engineering \\%   V\"{a}xj\"{o} University \\%   SE-35195, V\"{a}xj\"{o}, Sweden \\%   {\tt nivre@msi.vxu.se} \And%   Noah A. Smith \\%   Language Technologies Institute \\%   Carnegie Mellon University \\%   Pittsburgh, PA 15213, USA\\%   {\tt nasmith@cs.cmu.edu}}\date{}\begin{document}\maketitle\begin{abstract}  The Natural Language Toolkit (\NLTK) is widely used for teaching  natural language processing to students majoring in linguists or  computer science.  This paper describes the design of \NLTK, and  reports on how it has been used effectively in classes that involve  a combination of linguists and computer scientists.\end{abstract}\section{Introduction}Natural Language Processing (\NLP) is often taught within the confinesof a single-semester course at advanced undergraduate level orpostgraduate level. Many instructors have found that it is difficultto cover both the theoretical and practical sides of the subject insuch a short span of time, especially when some of the students havelimited programming experience. Some courses focus on theory to theexclusion of practical exercises, and deprive students of thechallenge and excitement of writing programs to automatically processlanguage. Other courses are simply designed to teach programming forlinguists, and do not manage to cover any significant \NLP\ content. TheNatural Language Toolkit (\NLTK) was originally developed to addressthis problem, making it feasible to cover a substantial amount oftheory and practice within a single-semester course, for an audienceconsisting of both linguists and computer scientists.\NLTK\ is a suite of Python modulesdistributed under the GPL open source license from \url{nltk.org}.\NLTK\ comes with a large collection of corpora, extensivedocumentation, and hundreds of exercises.  It has been used in over 50university courses in more than 15countries.\footnote{\url{http://nltk.org/courses.html}}Since its inception in 2000(?), \NLTK\ has undergone considerableevolution, to a large extent under the influence of feedback from awide range of users. One feature which has turned out to beparticularly important is the development of the original HOWTO-style`tutorials` on \NLTK\ into a detailed, self-contained, online book(\url{ntlk.org/Book}). The book has been designed to stay in lock-stepwith the \NLTK\ code, and is intended to provide a major support ingetting students to learn \NLP\ by doing it. In consequence, webelieve \NLTK\ is unique in providing a comprehensive framework forstudents to develop a computational understanding of language.%  to learn about \NLP\ in the context of learning to% program. What sets it apart is the tight coupling of the% chapters and exercises with \NLTK, giving students --- even those with no% prior programming experience --- a practical introduction to NLP. Once% completing these materials, students are ready to attempt one of% the more advanced textbooks.This paper describes the design of \NLTK, and reports on how it hasbeen used effectively in classes that involve a combination oflinguists and computer scientists.  First we discuss aspects of thedesign of the toolkit that arose from our need to teach computationallinguistics to a multidisciplinary audience.  The next sectionscover three distinct challenges:getting started with a course (\S\ref{sec:getting-started});fostering classroom interaction (\S\ref{sec:classroom-interaction});and organizing student projects (\S\ref{sec:student-projects}).\section{Design Decisions Affecting Teaching}\label{sec:design}The original conception of \NLTK\  was to develop data structures,algorithms and methods for \NLP\ in code that was simple and clearenough that the basic principles could beeasily grasped by students manipulating and reading the code. Althoughthis is still a central aspect of \NLTK, with the benefit of hindsight wecan see that it is rather biased towards as CS audience. In ourexperience, the average linguistics student is not going to look atsignificant chunks of code --- it isn't what they care about, and theyprobably lack the self-confidence to poke around in sourcefiles. Instead, they are more interested in some or all of the following:\begin{itemize}\item understanding the algorithms at a relatively abstract level  (e.g., understanding $n$-gram based POS-tagging);\item using computational tools to perform analytic tasks from `core  linguistics' (e.g., writing a set of CFG productions to parse some  sentences);\item plugging together components to carry out a larger-scale task  (e.g., combining tokenization, POS-tagging and chunking to derive  subcategorization requirements of verbs in a corpus).\end{itemize}In a nutshell, the linguistics students typically want to \emph{use}the tools in the toolkit, but they don't want to take the tools apartand they don't expect to be able to devise new tools.\subsection{Python}We chose Python because it has a shallow learning curve, its syntaxand semantics are transparent, and it has good string-handlingfunctionality.  As an interpreted language, Python facilitatesinteractive exploration.  As an object-oriented language, Pythonpermits data and methods to be encapsulated and re-used easily.  Python comes with an extensivestandard library, including tools for graphical programming andnumerical processing.We have taken the step of incorporating a detailed introduction toPython programming in the \NLTK\ book, taking care to motivateprogramming constructs with linguistic examples. Extensive feedbackfrom students has been humbling, and revealed that for students withno prior programming experience, it is almost impossible toover-explain. Despite the difficulty of providing a completelyself-contained introduction to Python for linguists, we neverthelesshave also had very positive feedback, and in combination with theteaching techniques described below, have managed to bring alarge group of non-programmer students rapidly to a point where theycould carry out interesting and useful exercises in text processing.help function, access to \NLTK\ documentation on any module.Python itself fosters aninteractive style of teaching.  For instance, we've found it quitenatural to build up moderately complex programs in front of a class,with the weaker students transcribing it into a Python session ontheir laptop to satisfy themselves it works (but not necessarilyunderstanding everything they enter first time), while the strongerstudents quickly grasp the theoretical concepts and algorithms.  Whileboth groups can be served by the same presentation, they tend to askquite different questions.  However, this is addressed by dividingthem into smaller clusters and having TAs visit them separately todiscuss issues arising from the content.\subsection{Coding Requirements}Consistency, extensibility, simplicity, modularity.Non-requirements: comprehensiveness, efficiency, cleverness.\cite{LoperBird02}Code is readable -- a student who doesn't understand the maths of HMMs,smoothing, etc can get another angle on it via the code.\subsection{Naming}One issue which has absorbed a considerable amount of attention is thenaming of user-oriented functions in \NLTK. To a large extent, thesystem of naming \emph{is} the user interface to the toolkit, and it isimportant that users should be able to guess what action might beperformed by a given function. Consequently, naming conventions needto be consistent and semantically transparent. At the same time, there is acountervailing pressure for relatively succinct names, since excessive verbositycan also hinder comprehension and usability. An additionalcomplication is that adopting an object-oriented style of programmingmay be well-motivated for a number of reasons but neverthelessbaffling to the linguist student. For example, although it isperfectly respectable to invoke an instance method\texttt{WhitespaceTokenizer().tokenize(text)} (for some inputstring \texttt{text}), from a presentational point of view, \texttt{WhitespaceTokenizer(text)} works a lot better.\subsection{Corpus Access}Uniform corpus access.  After importing \NLTK, one can access all the corporausing the \texttt{nltk.corpus} module:{\small\begin{verbatim}>>> nltk.corpus.NAME.METHOD(PARAMETERS)\end{verbatim}}Here, \texttt{NAME} is any of the 45 corpora distributed with NLTK, includingparsed, POS-tagged, plain text, categorized text, and lexicons.\footnote{\url{http://nltk.org/corpora.html}}The \texttt{METHOD} can be any of\texttt{raw}, for the raw contents of the corpus;\texttt{words}, for a list of tokenized words;\texttt{sents}, for the same list grouped into sentences;\texttt{tagged\_words}, for a list of (word,tag) pairs;\texttt{tagged\_sents}, for the same list grouped into sentences;\texttt{parsed\_sents}, for a list of parse trees.The following example shows how to access the Brown Corpus:{\small\begin{verbatim}>>> nltk.corpus.brown.tagged_words()[('The', 'at'), ('Fulton', 'np-tl'),('County', 'nn-tl'), ('Grand', 'jj-tl'),('Jury', 'nn-tl'), ('said', 'vbd'), ...]\end{verbatim}}Note that not all methods are available for all corpora (e.g., we canask for the words from just about any corpus, but only for\texttt{parsed\_sents} from the parsed corpora).The \texttt{PARAMETERS} are typically used to restrict the amount of material returned,e.g. to a section of a corpus, or an individual corpus file.\subsection{Diversity of Programming Experience}Self-paced learning: tutorials, hundreds of graded exercises (self-evaluation)\NLTK\ supports assignments of varying difficulty and scope. In thesimplest assignments, students experiment with existing components toperform a wide variety of \NLP\ tasks. This may involve no programmingat all, in the case of the existing demonstrations, or simply changinga line or two of program code. As students become more familiar withthe toolkit they can be asked to modify existing components or tocreate complete systems out of existing components. \NLTK\ also providesstudents with a flexible framework for advanced projects, such asdeveloping a multi-component system, by integrating and extending \NLTK\components, and adding on entirely new components. Here \NLTK\ helps byproviding standard implementations of all the basic data structuresand algorithms, interfaces to standard corpora, substantial corpussamples, and a flexible and extensible architecture.\section{Getting Started}\label{sec:getting-started}\subsection{The First Lecture}Motivating and exemplifying NLP to a mixed audience.Some possible starting points:a) the holy grail: machines that understand language:- how this relates to linguists (writing programs to help us  understand the human language faculty)- how this relates to CS students: technologies that demonstrate some level of NLU:  SLDS, QA, Summarization, MTb) richness of language- extracting information from the web (economic incentive)- the recursive structure of natural language (prospects for applying  parsing techniques normally used for compilers to natural language)- studying large corpora  (no end to corpus formats, incompatible tools (linguists)  exploratory data analysis (find patterns not supported by existing software))\subsection{CDROM}ISO image -- give out CDs\subsection{First Assignment}Breaking the ice; force people to learn Python.\section{Classroom Interaction}\label{sec:classroom-interaction}\subsection{Demonstrations with the Python Interpreter}try it and seeNLTK book has many examples...An effective way to deliver the materials is through interactivepresentation of the examples, entering them at the Python prompt,observing what they do, and modifying them to explore some empiricalor theoretical question.\subsection{Interactive Demonstrations}A significant fraction of any \NLP\ syllabus covers fundamental datastructures and algorithms. These are usually taught with the help offormal notations and complex diagrams. Large trees and charts arecopied onto the board and edited in tedious slow motion, orlaboriously prepared for presentation slides. It is more effective touse live demonstrations in which those diagrams are generated andupdated automatically. \NLTK\ provides interactive graphical userinterfaces, making it possible to view program state and to studyprogram execution step-by-step. Most NLTK components have ademonstration mode, and will perform an interesting task withoutrequiring any special input from the user. It is even possible to makeminor modifications to programs in response to ``what if'' questions. Inthis way, students learn the mechanics of NLP quickly, gain deeperinsights into the data structures and algorithms, and acquire newproblem-solving skills.\subsection{Small Group Discussion}animate this with a quiz, presented as a slide or a handout, giving code samples and asking what they do.\subsection{Chatroom}useful during intensive summer program; otherwise couldn't be staffed adequately\section{Student Projects}\label{sec:student-projects}Group projects involving a mixture of linguists and CS students:initial appeal is that a CS student will help the linguist student with programming,and vice versa.  However, there's acomplex dynamic, unpredictable success, linguist probably won't get to programin the interests of a good project mark.Multi-stage project mandating stages that require linguistic and CS content: difficultto foster continuous collaboration, more likely to get e.g. parser being developed bya CS team member, then thrown over the wall to a linguist member to develop a grammar.Instead, believe it is more productive in the context of a single-semester introductorycourse to have students work on their own projects.  Devise distinct projects forstudents depending on background.  Provide a list and give them the option of proposingother projects.\url{http://nltk.org/projects.html}Peer review (including code review) to improve quality of programming, andemphasize the communicative dimension of programming.(Even grade a student on the quality of his/her peer review of another student.)\bibliographystyle{acl}\bibliography{acl-08}\end{document}