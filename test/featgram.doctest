=========================
 Feature Grammar Parsing
=========================

 Grammars can be parsed from strings.

    >>> import nltk
    >>> from nltk import cfg, parse
    >>> g = """
    ... % start DP
    ... DP[agr=?a] -> D[agr=?a] N[agr=?a]
    ... D[agr=[num='sg', pers=3]] -> 'this' | 'that'
    ... D[agr=[num='pl', pers=3]] -> 'these' | 'those'
    ... D[agr=[num='pl', pers=1]] -> 'we'
    ... D[agr=[pers=2]] -> 'you'
    ... N[agr=[num='sg', gend='m']] -> 'boy'
    ... N[agr=[num='pl', gend='m']] -> 'boys'
    ... N[agr=[num='sg', gend='f']] -> 'girl'
    ... N[agr=[num='pl', gend='f']] -> 'girls'
    ... N[agr=[num='sg']] -> 'student'
    ... N[agr=[num='pl']] -> 'students'
    ... """
    >>> (grammar, lexicon) = cfg.parse_fcfg(g)
    >>> tokens = 'these girls'.split()
    >>> parser = parse.FeatureEarleyChartParser(grammar, lexicon)
    >>> trees = parser.get_parse_list(tokens)
    >>> for tree in trees: print tree
    (DP[agr=[gend='f', num='pl', pers=3]]
      (D[agr=[num='pl', pers=3]] these)
      (N[agr=[gend='f', num='pl']] girls))

In general, when we are trying to develop even a very small grammar,
it is convenient to put the rules in a file where they can be edited,
tested and revised. Assuming we have saved feat0cfg_ as a file named
``'feat0.cfg'``, the function ``GrammarFile.read_file()`` allows us to
read the grammar into NLTK, ready for use in parsing.

 
    >>> cp = parse.load_earley('grammars/feat0.fcfg', trace=2)
    >>> sent = 'Kim likes children'
    >>> tokens = sent.split()
    >>> tokens
    ['Kim', 'likes', 'children']
    >>> trees = cp.get_parse_list(tokens)
              |.K.l.c.|
    Processing queue 0
    Predictor |> . . .| S[] -> * NP[NUM=?n] VP[NUM=?n] {}
    Predictor |> . . .| NP[NUM=?n] -> * N[NUM=?n] {}
    Predictor |> . . .| NP[NUM=?n] -> * PropN[NUM=?n] {}
    Predictor |> . . .| NP[NUM=?n] -> * Det[NUM=?n] N[NUM=?n] {}
    Predictor |> . . .| NP[NUM='pl'] -> * N[NUM='pl'] {}
    Scanner   |[-] . .| [0:1] 'Kim'
    Scanner   |[-] . .| PropN[NUM='sg'] -> 'Kim' *
    Processing queue 1
    Completer |[-] . .| NP[NUM='sg'] -> PropN[NUM='sg'] *
    Completer |[-> . .| S[] -> NP[NUM=?n] * VP[NUM=?n] {?n: 'sg'}
    Predictor |. > . .| VP[NUM=?n, TENSE=?t] -> * IV[NUM=?n, TENSE=?t] {}
    Predictor |. > . .| VP[NUM=?n, TENSE=?t] -> * TV[NUM=?n, TENSE=?t] NP[] {}
    Scanner   |. [-] .| [1:2] 'likes'
    Scanner   |. [-] .| TV[NUM='sg', TENSE='pres'] -> 'likes' *
    Processing queue 2
    Completer |. [-> .| VP[NUM=?n, TENSE=?t] -> TV[NUM=?n, TENSE=?t] * NP[] {?n: 'sg', ?t: 'pres'}
    Predictor |. . > .| NP[NUM=?n] -> * N[NUM=?n] {}
    Predictor |. . > .| NP[NUM=?n] -> * PropN[NUM=?n] {}
    Predictor |. . > .| NP[NUM=?n] -> * Det[NUM=?n] N[NUM=?n] {}
    Predictor |. . > .| NP[NUM='pl'] -> * N[NUM='pl'] {}
    Scanner   |. . [-]| [2:3] 'children'
    Scanner   |. . [-]| N[NUM='pl'] -> 'children' *
    Processing queue 3
    Completer |. . [-]| NP[NUM='pl'] -> N[NUM='pl'] *
    Completer |. [---]| VP[NUM='sg', TENSE='pres'] -> TV[NUM='sg', TENSE='pres'] NP[] *
    Completer |[=====]| S[] -> NP[NUM='sg'] VP[NUM='sg'] *
    Completer |[=====]| INIT[] -> S[] *
    >>> for tree in trees: print tree
    (S[]
      (NP[NUM='sg'] (PropN[NUM='sg'] Kim))
      (VP[NUM='sg', TENSE='pres']
        (TV[NUM='sg', TENSE='pres'] likes)
        (NP[NUM='pl'] (N[NUM='pl'] children))))

Feature structures in NLTK are ... Atomic feature values can be strings or
integers.

    >>> fs1 = nltk.FeatStruct(TENSE='past', NUM='sg')
    >>> print fs1
    [ NUM   = 'sg'   ]
    [ TENSE = 'past' ]

We can think of a feature structure as being like a Python dictionary,
and access its values by indexing in the usual way.

    >>> fs1 = nltk.FeatStruct(PER=3, NUM='pl', GND='fem')
    >>> print fs1['GND']
    fem

We can also define feature structures which have complex values, as
discussed earlier.

    >>> fs2 = nltk.FeatStruct(POS='N', AGR=fs1)
    >>> print fs2
    [       [ GND = 'fem' ] ]
    [ AGR = [ NUM = 'pl'  ] ]
    [       [ PER = 3     ] ]
    [                       ]
    [ POS = 'N'             ]
    >>> print fs2['AGR']
    [ GND = 'fem' ]
    [ NUM = 'pl'  ]
    [ PER = 3     ]
    >>> print fs2['AGR']['PER']
    3

Feature structures can also be constructed using the ``parse()``
method of the ``nltk.FeatStruct" class. Note that in this case, atomic
feature values do not need to be enclosed in quotes.
    
    >>> f1 = nltk.FeatStruct("[NUMBER = sg]")
    >>> f2 = nltk.FeatStruct("[PERSON = 3]")
    >>> print nltk.unify(f1, f2)
    [ NUMBER = 'sg' ]
    [ PERSON = 3    ]

    >>> f1 = nltk.FeatStruct("[A = [B = b, D = d]]")
    >>> f2 = nltk.FeatStruct("[A = [C = c, D = d]]")
    >>> print nltk.unify(f1, f2)
    [     [ B = 'b' ] ]
    [ A = [ C = 'c' ] ]
    [     [ D = 'd' ] ]


Feature Structures as Graphs
----------------------------

Feature structures are not inherently tied to linguistic objects; they are
general purpose structures for representing knowledge. For example, we
could encode information about a person in a feature structure:

    >>> person01 = nltk.FeatStruct("[NAME=Lee, TELNO='01 27 86 42 96',AGE=33]")
    >>> print person01
    [ AGE   = 33               ]
    [ NAME  = 'Lee'            ]
    [ TELNO = '01 27 86 42 96' ]

There are a number of notations for representing reentrancy in
matrix-style representations of feature structures. In NLTK, we adopt
the following convention: the first occurrence of a shared feature structure 
is prefixed with an integer in parentheses, such as ``(1)``, and any
subsequent reference to that structure uses the notation
``->(1)``, as shown below.

 
    >>> fs = nltk.FeatStruct("""[NAME=Lee, ADDRESS=(1)[NUMBER=74, STREET='rue Pascal'], 
    ...                               SPOUSE=[NAME=Kim, ADDRESS->(1)]]""")
    >>> print fs
    [ ADDRESS = (1) [ NUMBER = 74           ] ]
    [               [ STREET = 'rue Pascal' ] ]
    [                                         ]
    [ NAME    = 'Lee'                         ]
    [                                         ]
    [ SPOUSE  = [ ADDRESS -> (1)  ]           ]
    [           [ NAME    = 'Kim' ]           ]

There can be any number of tags within a single feature structure.

    >>> fs3 = nltk.FeatStruct("[A=(1)[B=b], C=(2)[], D->(1), E->(2)]")
    >>> print fs3
    [ A = (1) [ B = 'b' ] ]
    [                     ]
    [ C = (2) []          ]
    [                     ]
    [ D -> (1)            ]
    [ E -> (2)            ]
    >>> fs1 = nltk.FeatStruct(NUMBER=74, STREET='rue Pascal')
    >>> fs2 = nltk.FeatStruct(CITY='Paris')
    >>> print nltk.unify(fs1, fs2)
    [ CITY   = 'Paris'      ]
    [ NUMBER = 74           ]
    [ STREET = 'rue Pascal' ]

Unification is symmetric:

    >>> nltk.unify(fs1, fs2) == nltk.unify(fs2, fs1)
    True

Unification is commutative:

    >>> fs3 = nltk.FeatStruct(TELNO='01 27 86 42 96')
    >>> nltk.unify(nltk.unify(fs1, fs2), fs3) == nltk.unify(fs1, nltk.unify(fs2, fs3))
    True

Unification between `FS`:math:\ :subscript:`0` and `FS`:math:\
:subscript:`1` will fail if the two feature structures share a path |pi|,
but the value of |pi| in `FS`:math:\ :subscript:`0` is a distinct
atom from the value of |pi| in `FS`:math:\ :subscript:`1`. In NLTK,
this is implemented by setting the result of unification to be
``None``.

    >>> fs0 = nltk.FeatStruct(A='a')
    >>> fs1 = nltk.FeatStruct(A='b')
    >>> print nltk.unify(fs0, fs1)
    None

Now, if we look at how unification interacts with structure-sharing,
things become really interesting.



    >>> fs0 = nltk.FeatStruct("""[NAME=Lee, 
    ...                                ADDRESS=[NUMBER=74, 
    ...                                         STREET='rue Pascal'], 
    ...                                SPOUSE= [NAME=Kim,
    ...                                         ADDRESS=[NUMBER=74, 
    ...                                                  STREET='rue Pascal']]]""")
    >>> print fs0
    [ ADDRESS = [ NUMBER = 74           ]               ]
    [           [ STREET = 'rue Pascal' ]               ]
    [                                                   ]
    [ NAME    = 'Lee'                                   ]
    [                                                   ]
    [           [ ADDRESS = [ NUMBER = 74           ] ] ]
    [ SPOUSE  = [           [ STREET = 'rue Pascal' ] ] ]
    [           [                                     ] ]
    [           [ NAME    = 'Kim'                     ] ]


    >>> fs1 = nltk.FeatStruct("[SPOUSE=[ADDRESS=[CITY=Paris]]]")
    >>> print nltk.unify(fs0, fs1)
    [ ADDRESS = [ NUMBER = 74           ]               ]
    [           [ STREET = 'rue Pascal' ]               ]
    [                                                   ]
    [ NAME    = 'Lee'                                   ]
    [                                                   ]
    [           [           [ CITY   = 'Paris'      ] ] ]
    [           [ ADDRESS = [ NUMBER = 74           ] ] ]
    [ SPOUSE  = [           [ STREET = 'rue Pascal' ] ] ]
    [           [                                     ] ]
    [           [ NAME    = 'Kim'                     ] ]

    >>> fs2 = nltk.FeatStruct("""[NAME=Lee, ADDRESS=(1)[NUMBER=74, STREET='rue Pascal'],
    ...                                SPOUSE=[NAME=Kim, ADDRESS->(1)]]""")

 
    >>> print fs2
    [ ADDRESS = (1) [ NUMBER = 74           ] ]
    [               [ STREET = 'rue Pascal' ] ]
    [                                         ]
    [ NAME    = 'Lee'                         ]
    [                                         ]
    [ SPOUSE  = [ ADDRESS -> (1)  ]           ]
    [           [ NAME    = 'Kim' ]           ]


    >>> print nltk.unify(fs2, fs1)
    [               [ CITY   = 'Paris'      ] ]
    [ ADDRESS = (1) [ NUMBER = 74           ] ]
    [               [ STREET = 'rue Pascal' ] ]
    [                                         ]
    [ NAME    = 'Lee'                         ]
    [                                         ]
    [ SPOUSE  = [ ADDRESS -> (1)  ]           ]
    [           [ NAME    = 'Kim' ]           ]


    >>> fs1 = nltk.FeatStruct("[ADDRESS1=[NUMBER=74, STREET='rue Pascal']]")
    >>> fs2 = nltk.FeatStruct("[ADDRESS1=?x, ADDRESS2=?x]")
    >>> print fs2
    [ ADDRESS1 = ?x ]
    [ ADDRESS2 = ?x ]
    >>> print nltk.unify(fs1, fs2)
    [ ADDRESS1 = (1) [ NUMBER = 74           ] ]
    [                [ STREET = 'rue Pascal' ] ]
    [                                          ]
    [ ADDRESS2 -> (1)                          ]

 


    >>> sent = 'who do you claim that you like'
    >>> tokens = sent.split()
    >>> cp = parse.load_earley('grammars/feat1.fcfg', trace=1)
    >>> trees = cp.get_parse_list(tokens)
              |.w.d.y.c.t.y.l.|
    Scanner   |[-] . . . . . .| [0:1] 'who'
    Scanner   |[-] . . . . . .| NP[+WH] -> 'who' *
    Completer |[-> . . . . . .| S[-INV] -> NP[] * S[]/NP[] {}
    Scanner   |. [-] . . . . .| [1:2] 'do'
    Scanner   |. [-] . . . . .| V[+AUX, SUBCAT=3] -> 'do' *
    Completer |. [-> . . . . .| S[+INV]/?x[] -> V[+AUX] * NP[] VP[]/?x[] {}
    Scanner   |. . [-] . . . .| [2:3] 'you'
    Scanner   |. . [-] . . . .| NP[-WH] -> 'you' *
    Completer |. [---> . . . .| S[+INV]/?x[] -> V[+AUX] NP[] * VP[]/?x[] {}
    Scanner   |. . . [-] . . .| [3:4] 'claim'
    Scanner   |. . . [-] . . .| V[-AUX, SUBCAT=2] -> 'claim' *
    Completer |. . . [-> . . .| VP[]/?x[] -> V[-AUX, SUBCAT=2] * S-BAR[]/?x[] {}
    Scanner   |. . . . [-] . .| [4:5] 'that'
    Scanner   |. . . . [-] . .| Comp[] -> 'that' *
    Completer |. . . . [-> . .| S-BAR[]/?x[] -> Comp[] * S[-INV]/?x[] {}
    Scanner   |. . . . . [-] .| [5:6] 'you'
    Scanner   |. . . . . [-] .| NP[-WH] -> 'you' *
    Completer |. . . . . [-> .| S[-INV]/?x[] -> NP[] * VP[]/?x[] {}
    Scanner   |. . . . . . [-]| [6:7] 'like'
    Scanner   |. . . . . . [-]| V[-AUX, SUBCAT=1] -> 'like' *
    Completer |. . . . . . [->| VP[]/?x[] -> V[-AUX, SUBCAT=1] * NP[]/?x[] {}
    Completer |. . . . . . [-]| VP[]/NP[] -> V[-AUX, SUBCAT=1] NP[]/NP[] *
    Completer |. . . . . [---]| S[-INV]/NP[] -> NP[] VP[]/NP[] *
    Completer |. . . . [-----]| S-BAR[]/NP[] -> Comp[] S[-INV]/NP[] *
    Completer |. . . [-------]| VP[]/NP[] -> V[-AUX, SUBCAT=2] S-BAR[]/NP[] *
    Completer |. [-----------]| S[+INV]/NP[] -> V[+AUX] NP[] VP[]/NP[] *
    Completer |[=============]| S[-INV] -> NP[] S[]/NP[] *
    Completer |[=============]| INIT[] -> S[] *
    >>> for tree in trees: print tree
    (S[-INV]
      (NP[+WH] who)
      (S[+INV]/NP[]
        (V[+AUX, SUBCAT=3] do)
        (NP[-WH] you)
        (VP[]/NP[]
          (V[-AUX, SUBCAT=2] claim)
          (S-BAR[]/NP[]
            (Comp[] that)
            (S[-INV]/NP[]
              (NP[-WH] you)
              (VP[]/NP[] (V[-AUX, SUBCAT=1] like) (NP[]/NP[] )))))))


Let's load a German grammar:

    >>> cp = parse.load_earley('grammars/german.fcfg', trace=0)
    >>> sent = 'die katze sieht den hund'
    >>> tokens = sent.split()
    >>> trees = cp.get_parse_list(tokens)
    >>> for tree in trees: print tree
    (S[]
      (NP[AGR=[GND='fem', NUM='sg', PER=3], CASE='nom']
        (Det[AGR=[GND='fem', NUM='sg', PER=3], CASE='nom'] die)
        (N[AGR=[GND='fem', NUM='sg', PER=3]] katze))
      (VP[AGR=[NUM='sg', PER=3]]
        (TV[AGR=[NUM='sg', PER=3], OBJCASE='acc'] sieht)
        (NP[AGR=[GND='masc', NUM='sg', PER=3], CASE='acc']
          (Det[AGR=[GND='masc', NUM='sg', PER=3], CASE='acc'] den)
          (N[AGR=[GND='masc', NUM='sg', PER=3]] hund))))


